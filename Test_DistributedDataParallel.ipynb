{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import DataParallel, Linear\n",
    "import torchvision\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import numpy as np\n",
    "import  matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook DistributedDataParallel_script.ipynb to script\n",
      "[NbConvertApp] Writing 7913 bytes to DistributedDataParallel_script.py\n",
      "#!/usr/bin/env python\n",
      "# coding: utf-8\n",
      "\n",
      "# In[ ]:\n",
      "\n",
      "\n",
      "import torch\n",
      "from torch.nn import DataParallel, Linear\n",
      "import torchvision\n",
      "from torch.utils.data.dataset import Dataset\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to script DistributedDataParallel_script.ipynb\n",
    "!head DistributedDataParallel_script.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single GPU training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: ./MNIST_data\n",
      "    Split: Train\n",
      "(784,) 5\n",
      "args =  Namespace(batch=16, epochs=1, issingle=True, lr=0.001, rank=None, size=None)\n",
      "Single GPU training\n",
      "using device cuda\n",
      "100%|██████████████████████████████████████| 3750/3750 [00:12<00:00, 296.57it/s]\n",
      "loss at epoch 0 is 0.01112106442451477\n",
      "shape = torch.Size([128, 784]), mean of values = -0.003827874781563878\n",
      "shape = torch.Size([128]), mean of values = 0.015357923693954945\n",
      "shape = torch.Size([64, 128]), mean of values = 0.008210898377001286\n",
      "shape = torch.Size([64]), mean of values = 0.043486520648002625\n",
      "shape = torch.Size([10, 64]), mean of values = -0.02711520902812481\n",
      "shape = torch.Size([10]), mean of values = 0.010919672437012196\n",
      "CPU times: user 203 ms, sys: 64 ms, total: 267 ms\n",
      "Wall time: 16.3 s\n"
     ]
    }
   ],
   "source": [
    "%time !python DistributedDataParallel_script.py --issingle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single GPU distributed training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: ./MNIST_data\n",
      "    Split: Train\n",
      "(784,) 5\n",
      "args =  Namespace(batch=16, epochs=1, issingle=False, lr=0.001, rank=0, size=1)\n",
      "starting distibuted training Namespace(batch=16, epochs=1, issingle=False, lr=0.001, rank=0, size=1)\n",
      "inside train_distrib rank 0 and world_size 1\n",
      "setting up\n",
      "using device 0\n",
      "100%|██████████████████████████████████████| 3750/3750 [00:14<00:00, 254.07it/s]\n",
      "loss at epoch 0 is 0.0966588482260704\n",
      "shape = torch.Size([128, 784]), mean of values = -0.0026552591007202864\n",
      "shape = torch.Size([128]), mean of values = 0.020683109760284424\n",
      "shape = torch.Size([64, 128]), mean of values = 0.008393129333853722\n",
      "shape = torch.Size([64]), mean of values = 0.025294966995716095\n",
      "shape = torch.Size([10, 64]), mean of values = -0.028980279341340065\n",
      "shape = torch.Size([10]), mean of values = -0.028823498636484146\n",
      "CPU times: user 247 ms, sys: 41.8 ms, total: 288 ms\n",
      "Wall time: 18.4 s\n"
     ]
    }
   ],
   "source": [
    "%time !python DistributedDataParallel_script.py --rank 0 --size 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Multi GPU distributed training\n",
    "Verify loss is same"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: ./MNIST_data\n",
      "    Split: Train\n",
      "(784,) 5\n",
      "args =  Namespace(batch=8, epochs=2, issingle=False, lr=0.001, rank=0, size=2)\n",
      "starting distibuted training Namespace(batch=8, epochs=2, issingle=False, lr=0.001, rank=0, size=2)\n",
      "inside train_distrib rank 0 and world_size 2\n",
      "setting up\n",
      "using device 0\n",
      "100%|██████████████████████████████████████| 3750/3750 [00:14<00:00, 252.73it/s]\n",
      "loss at epoch 0 is 0.17599113285541534\n",
      "shape = torch.Size([128, 784]), mean of values = -0.0026919872034341097\n",
      "shape = torch.Size([128]), mean of values = 0.021903974935412407\n",
      "shape = torch.Size([64, 128]), mean of values = 0.00897801574319601\n",
      "shape = torch.Size([64]), mean of values = 0.027450013905763626\n",
      "shape = torch.Size([10, 64]), mean of values = -0.028402984142303467\n",
      "shape = torch.Size([10]), mean of values = -0.028803611174225807\n",
      "100%|██████████████████████████████████████| 3750/3750 [00:14<00:00, 256.25it/s]\n",
      "loss at epoch 1 is 0.02908986806869507\n",
      "shape = torch.Size([128, 784]), mean of values = -0.004256885964423418\n",
      "shape = torch.Size([128]), mean of values = 0.022111745551228523\n",
      "shape = torch.Size([64, 128]), mean of values = 0.006849308498203754\n",
      "shape = torch.Size([64]), mean of values = 0.03356897830963135\n",
      "shape = torch.Size([10, 64]), mean of values = -0.03563050553202629\n",
      "shape = torch.Size([10]), mean of values = -0.03182206302881241\n",
      "CPU times: user 470 ms, sys: 140 ms, total: 609 ms\n",
      "Wall time: 39.1 s\n"
     ]
    }
   ],
   "source": [
    "%time !python DistributedDataParallel_script.py --rank 0 --size 2 --batch 8 --epochs 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
