{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import DataParallel, Linear\n",
    "import torchvision\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import numpy as np\n",
    "import  matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook DistributedDataParallel_script.ipynb to script\n",
      "[NbConvertApp] Writing 11661 bytes to DistributedDataParallel_script.py\n",
      "#!/usr/bin/env python\n",
      "# coding: utf-8\n",
      "\n",
      "# In[5]:\n",
      "\n",
      "\n",
      "import torch\n",
      "from torch.nn import DataParallel, Linear\n",
      "import torchvision\n",
      "from torch.utils.data.dataset import Dataset\n"
     ]
    }
   ],
   "source": [
    "!jupyter nbconvert --to script DistributedDataParallel_script.ipynb\n",
    "!head DistributedDataParallel_script.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single GPU training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args =  Namespace(backend='gloo', batch=16, epochs=1, global_rank=None, isaml=False, issingle=True, local_rank=None, lr=0.001, size=None)\n",
      "Single GPU training\n",
      "loading data\n",
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: ./MNIST_data\n",
      "    Split: Train\n",
      "60000 10000\n",
      "(784,) 5\n",
      "using device cuda\n",
      "100%|██████████████████████████████████████| 3750/3750 [00:12<00:00, 295.50it/s]\n",
      "loss at epoch 0 is 0.013191968202590942\n",
      "shape = torch.Size([128, 784]), mean of values = -0.003071286715567112\n",
      "shape = torch.Size([128]), mean of values = 0.021458515897393227\n",
      "shape = torch.Size([64, 128]), mean of values = 0.00920057762414217\n",
      "shape = torch.Size([64]), mean of values = 0.035079047083854675\n",
      "shape = torch.Size([10, 64]), mean of values = -0.024419544264674187\n",
      "shape = torch.Size([10]), mean of values = -0.017619147896766663\n",
      "100%|████████████████████████████████████████| 625/625 [00:01<00:00, 504.37it/s]\n",
      "[7. 2. 1. 0. 4. 1. 4. 9. 5. 9.] [7. 2. 1. 0. 4. 1. 4. 9. 5. 9.]\n",
      "validation loss is 0.15309744182825089\n",
      "validation accuracy is 0.9495\n",
      "CPU times: user 185 ms, sys: 86.9 ms, total: 272 ms\n",
      "Wall time: 17 s\n"
     ]
    }
   ],
   "source": [
    "%time !python DistributedDataParallel_script.py --issingle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single GPU distributed training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args =  Namespace(backend='gloo', batch=16, epochs=1, global_rank=0, isaml=False, issingle=False, local_rank=0, lr=0.001, size=1)\n",
      "starting distibuted training Namespace(backend='gloo', batch=16, epochs=1, global_rank=0, isaml=False, issingle=False, local_rank=0, lr=0.001, size=1)\n",
      "inside train_distrib rank 0 and world_size 1\n",
      "loading data\n",
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: ./MNIST_data/0/\n",
      "    Split: Train\n",
      "60000 10000\n",
      "(784,) 5\n",
      "setting up\n",
      "MASTER_ADDR = localhost\n",
      "MASTER_PORT = 12355\n",
      "using device 0\n",
      "100%|██████████████████████████████████████| 3750/3750 [00:14<00:00, 251.31it/s]\n",
      "loss at epoch 0 is 0.0966588482260704\n",
      "shape = torch.Size([128, 784]), mean of values = -0.0026552591007202864\n",
      "shape = torch.Size([128]), mean of values = 0.020683109760284424\n",
      "shape = torch.Size([64, 128]), mean of values = 0.008393129333853722\n",
      "shape = torch.Size([64]), mean of values = 0.025294966995716095\n",
      "shape = torch.Size([10, 64]), mean of values = -0.028980279341340065\n",
      "shape = torch.Size([10]), mean of values = -0.028823498636484146\n",
      "100%|████████████████████████████████████████| 625/625 [00:01<00:00, 494.73it/s]\n",
      "[7. 2. 1. 0. 4. 1. 4. 9. 6. 9.] [7. 2. 1. 0. 4. 1. 4. 9. 5. 9.]\n",
      "validation loss is 0.12292282446026802\n",
      "validation accuracy is 0.9606\n",
      "CPU times: user 223 ms, sys: 73.7 ms, total: 296 ms\n",
      "Wall time: 19.3 s\n"
     ]
    }
   ],
   "source": [
    "%time !python DistributedDataParallel_script.py --local_rank 0 --global_rank 0 --size 1 --backend 'gloo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args =  Namespace(backend='nccl', batch=16, epochs=1, global_rank=0, isaml=False, issingle=False, local_rank=0, lr=0.001, size=1)\n",
      "starting distibuted training Namespace(backend='nccl', batch=16, epochs=1, global_rank=0, isaml=False, issingle=False, local_rank=0, lr=0.001, size=1)\n",
      "inside train_distrib rank 0 and world_size 1\n",
      "loading data\n",
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: ./MNIST_data/0/\n",
      "    Split: Train\n",
      "60000 10000\n",
      "(784,) 5\n",
      "setting up\n",
      "MASTER_ADDR = localhost\n",
      "MASTER_PORT = 12355\n",
      "using device 0\n",
      "100%|██████████████████████████████████████| 3750/3750 [00:14<00:00, 267.42it/s]\n",
      "loss at epoch 0 is 0.0966588482260704\n",
      "shape = torch.Size([128, 784]), mean of values = -0.0026552591007202864\n",
      "shape = torch.Size([128]), mean of values = 0.020683109760284424\n",
      "shape = torch.Size([64, 128]), mean of values = 0.008393129333853722\n",
      "shape = torch.Size([64]), mean of values = 0.025294966995716095\n",
      "shape = torch.Size([10, 64]), mean of values = -0.028980279341340065\n",
      "shape = torch.Size([10]), mean of values = -0.028823498636484146\n",
      "100%|████████████████████████████████████████| 625/625 [00:01<00:00, 510.09it/s]\n",
      "[7. 2. 1. 0. 4. 1. 4. 9. 6. 9.] [7. 2. 1. 0. 4. 1. 4. 9. 5. 9.]\n",
      "validation loss is 0.12292282446026802\n",
      "validation accuracy is 0.9606\n",
      "CPU times: user 210 ms, sys: 66.2 ms, total: 276 ms\n",
      "Wall time: 18.4 s\n"
     ]
    }
   ],
   "source": [
    "%time !python DistributedDataParallel_script.py --local_rank 0 --global_rank 0 --size 1 --backend 'nccl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args =  Namespace(backend='gloo', batch=8, epochs=1, global_rank=0, isaml=False, issingle=False, local_rank=0, lr=0.001, size=2)\n",
      "starting distibuted training Namespace(backend='gloo', batch=8, epochs=1, global_rank=0, isaml=False, issingle=False, local_rank=0, lr=0.001, size=2)\n",
      "inside train_distrib rank 0 and world_size 2\n",
      "loading data\n",
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: ./MNIST_data/0/\n",
      "    Split: Train\n",
      "60000 10000\n",
      "(784,) 5\n",
      "setting up\n",
      "MASTER_ADDR = localhost\n",
      "MASTER_PORT = 12355\n",
      "using device 0\n",
      "100%|██████████████████████████████████████| 3750/3750 [00:15<00:00, 247.44it/s]\n",
      "loss at epoch 0 is 0.17599113285541534\n",
      "shape = torch.Size([128, 784]), mean of values = -0.0026919872034341097\n",
      "shape = torch.Size([128]), mean of values = 0.021903974935412407\n",
      "shape = torch.Size([64, 128]), mean of values = 0.00897801574319601\n",
      "shape = torch.Size([64]), mean of values = 0.027450013905763626\n",
      "shape = torch.Size([10, 64]), mean of values = -0.028402984142303467\n",
      "shape = torch.Size([10]), mean of values = -0.028803611174225807\n",
      "100%|██████████████████████████████████████| 1250/1250 [00:01<00:00, 743.03it/s]\n",
      "[7. 2. 1. 0. 4. 1. 4. 9. 6. 9.] [7. 2. 1. 0. 4. 1. 4. 9. 5. 9.]\n",
      "validation loss is 0.12324176284074784\n",
      "validation accuracy is 0.9603\n",
      "CPU times: user 255 ms, sys: 114 ms, total: 369 ms\n",
      "Wall time: 23 s\n"
     ]
    }
   ],
   "source": [
    "%time !python DistributedDataParallel_script.py --local_rank 0 --global_rank 0 --size 2 --batch 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
