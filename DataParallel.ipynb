{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import DataParallel, Linear\n",
    "import torchvision\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import numpy as np\n",
    "import  matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Images to array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, mnist_dataset):\n",
    "        super(MyDataset,self).__init__()\n",
    "        self.mnist_dataset = mnist_dataset\n",
    "    def __getitem__(self, index):\n",
    "        item = self.mnist_dataset[index]\n",
    "        image = item[0]\n",
    "        label = item[1]\n",
    "        image_array = np.array(image,dtype = np.float32).reshape((-1))/255\n",
    "        return image_array, label\n",
    "    def __len__(self):\n",
    "        return len(self.mnist_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load MNIST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train, mnist_test, train_ds, test_ds = None,None,None,None\n",
    "def loaddata(rootdir = '../MNIST_data'):\n",
    "    global mnist_train, mnist_test, train_ds, test_ds\n",
    "    mnist_train = torchvision.datasets.MNIST(root = '../MNIST_data',train=True,download=True)\n",
    "    mnist_test = torchvision.datasets.MNIST(root = '../MNIST_data',train=False,download=True)\n",
    "\n",
    "    #A dataset returning pil image and label for each __getitem__ call\n",
    "    print(mnist_train)\n",
    "    train_ds = MyDataset(mnist_train)\n",
    "    test_ds = MyDataset(mnist_test)\n",
    "    print(len(train_ds), len(test_ds))\n",
    "    print(train_ds[0][0].shape,train_ds[0][1])\n",
    "    #train_ds[0][0][200:250],train_ds[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: ../MNIST_data\n",
      "    Split: Train\n",
      "60000 10000\n",
      "(784,) 5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x1440 with 7 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loaddata()\n",
    "plt.figure(figsize = (12,20))\n",
    "count = 7\n",
    "for i in range(count):\n",
    "    plt.subplot(1,count,i+1)\n",
    "    index = np.random.randint(0,len(mnist_train),(1,))[0]\n",
    "    im_array = np.asarray(mnist_train[index][0])\n",
    "    label = mnist_train[index][1]\n",
    "    imshow(im_array,cmap='gray',)\n",
    "    plt.title(str(index) + ' label:'+str(label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(batch=16, epochs=1, lr=0.001)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import argparse\n",
    "args = argparse.Namespace(\n",
    "    batch = 16,\n",
    "    lr = 0.001,\n",
    "    epochs =1\n",
    ")\n",
    "args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearModel(torch.nn.Module):\n",
    "    def __init__(self, input_size, output_size, verbose = False):\n",
    "        super(LinearModel,self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(input_size,64)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.fc2 = torch.nn.Linear(64,output_size)\n",
    "        self.verbose = verbose\n",
    "    def forward(self, X):\n",
    "        \n",
    "        if self.verbose:\n",
    "            print('X shape = {}, current cuda device = {}' \\\n",
    "                  .format(X.shape,torch.cuda.current_device() if torch.cuda.is_available() else 'NAN'))\n",
    "        return self.fc2(self.relu(self.fc1(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape = torch.Size([784]), current cuda device = 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 0.2608,  0.0098,  0.0033, -0.2133,  0.0187,  0.1146,  0.0105, -0.0431,\n",
       "         0.0566, -0.1077], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = LinearModel(784,10,True)\n",
    "m(torch.Tensor(train_ds[0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(train_ds, batch_size=args.batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([5, 0, 4, 1, 9, 2, 1, 3, 1, 4, 3, 5, 3, 6, 1, 7])]\n"
     ]
    }
   ],
   "source": [
    "#converts arrays into tensor and creates batches\n",
    "for data in dataloader:\n",
    "    print(data)\n",
    "    #print(model(data[0]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def train(model, optimizer, dataloader, device):\n",
    "    model.train()\n",
    "    print('using device',device)\n",
    "    losses = []\n",
    "    for epoch in range(args.epochs):\n",
    "        for x,y in tqdm(dataloader, position=0):\n",
    "            optimizer.zero_grad()\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "            yhat = model(x)\n",
    "            \n",
    "            loss = torch.nn.CrossEntropyLoss()(yhat, y)\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            losses.append(loss.item())\n",
    "            \n",
    "        print ('loss at epoch {} is {}'.format(epoch, losses[-1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader, device):\n",
    "    model.eval()\n",
    "    losses,preds,labels = [],np.empty((0,)),np.empty((0,))\n",
    "    for x,y in tqdm(dataloader, position=0):\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        yhat = model(x)\n",
    "        loss = torch.nn.CrossEntropyLoss()(yhat, y)\n",
    "        losses.append(loss.item())\n",
    "        \n",
    "        preds = np.hstack(  ( preds, np.argmax(yhat.detach().to('cpu').numpy(), axis = 1) .squeeze()) )\n",
    "        labels = np.hstack( (labels, y.to('cpu').numpy()) )\n",
    "        \n",
    "        #The losses are averaged across observations for each minibatch.\n",
    "    final_loss = sum(losses)/len(losses)\n",
    "    acc = accuracy(preds,labels)\n",
    "    print ('validation loss is {}'.format(final_loss))\n",
    "    print ('validation accuracy is {}'.format(acc))\n",
    "    \n",
    "\n",
    "def accuracy (preds, labels):\n",
    "    print(preds[:10], labels[:10])\n",
    "    return np.mean(preds == labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearModel(784,10)\n",
    "dataloader = DataLoader(train_ds, batch_size=args.batch)\n",
    "optimizer = torch.optim.Adam(params = model.parameters(), lr=args.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 20/3750 [00:00<00:19, 192.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 2942/3750 [00:15<00:04, 192.98it/s]"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cpu = torch.device('cpu')\n",
    "train(model,optimizer,dataloader, cpu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [00:01<00:00, 531.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7. 2. 1. 0. 4. 1. 4. 9. 5. 9.] [7. 2. 1. 0. 4. 1. 4. 9. 5. 9.]\n",
      "validation loss is 0.19258624857664108\n",
      "validation accuracy is 0.9378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "eval_dataloader = dataloader = DataLoader(test_ds, batch_size=args.batch)\n",
    "evaluate(model,eval_dataloader, cpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 35/3750 [00:00<00:10, 345.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3750/3750 [00:10<00:00, 352.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss at epoch 0 is 0.02700820565223694\n",
      "CPU times: user 10.6 s, sys: 120 ms, total: 10.8 s\n",
      "Wall time: 10.6 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "gpu = torch.device('cuda')\n",
    "model = LinearModel(784,10, verbose=False)\n",
    "model = model.to(gpu)\n",
    "dataloader = DataLoader(train_ds,batch_size=args.batch)\n",
    "\n",
    "optimizer = torch.optim.Adam(params = model.parameters(), lr=args.lr)\n",
    "\n",
    "%time train(model, optimizer, dataloader, gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [00:01<00:00, 520.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7. 2. 1. 0. 4. 1. 4. 9. 4. 9.] [7. 2. 1. 0. 4. 1. 4. 9. 5. 9.]\n",
      "validation loss is 0.19254192004203796\n",
      "validation accuracy is 0.9418\n",
      "CPU times: user 1.2 s, sys: 15.1 ms, total: 1.22 s\n",
      "Wall time: 1.2 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "eval_dataloader = dataloader = DataLoader(test_ds, batch_size=args.batch)\n",
    "%time evaluate(model,eval_dataloader, gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Higher batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 15/938 [00:00<00:06, 148.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:06<00:00, 152.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss at epoch 0 is 0.08182957768440247\n",
      "CPU times: user 6.13 s, sys: 137 ms, total: 6.26 s\n",
      "Wall time: 6.16 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataloader = DataLoader(train_ds,batch_size=args.batch *4)\n",
    "optimizer = torch.optim.Adam(params = model.parameters(), lr=args.lr*4)\n",
    "%time train(model, optimizer, dataloader, gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [00:01<00:00, 530.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7. 2. 1. 0. 4. 1. 4. 9. 5. 9.] [7. 2. 1. 0. 4. 1. 4. 9. 5. 9.]\n",
      "validation loss is 0.1630312618277967\n",
      "validation accuracy is 0.949\n",
      "CPU times: user 1.19 s, sys: 2.16 ms, total: 1.19 s\n",
      "Wall time: 1.18 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "eval_dataloader = dataloader = DataLoader(test_ds, batch_size=args.batch)\n",
    "%time evaluate(model,eval_dataloader, gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataParallel\n",
    "single process, multiple GPUs\n",
    "\n",
    "    This container parallelizes the application of the given :attr:`module` by\n",
    "    splitting the input across the specified devices by chunking in the batch\n",
    "    dimension (other objects will be copied once per device). In the forward\n",
    "    pass, the module is replicated on each device, and each replica handles a\n",
    "    portion of the input. During the backwards pass, gradients from each replica\n",
    "    are summed into the original module.\n",
    "\n",
    "Source: https://pytorch.org/docs/stable/_modules/torch/nn/parallel/data_parallel.html\n",
    "\n",
    "The batch size should be larger than the number of GPUs used.\n",
    "\n",
    "\n",
    "1. This is not very optimal as every forward run transfers the model and data portion between GPUs. \n",
    "1. Unless the processing in the module takes significant amount of time, this is not very useful.\n",
    "1. This is even slower than single GPU for simpler neural nets.\n",
    "\n",
    "        inputs, kwargs = self.scatter(inputs, kwargs, self.device_ids)\n",
    "        if len(self.device_ids) == 1:\n",
    "            return self.module(*inputs[0], **kwargs[0])\n",
    "        replicas = self.replicate(self.module, self.device_ids[:len(inputs)])\n",
    "        outputs = self.parallel_apply(replicas, inputs, kwargs)\n",
    "        return self.gather(outputs, self.output_device)\n",
    "\n",
    "Issues : https://medium.com/huggingface/training-larger-batches-practical-tips-on-1-gpu-multi-gpu-distributed-setups-ec88c3e51255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 17/3750 [00:00<00:22, 166.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3750/3750 [00:22<00:00, 167.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss at epoch 0 is 0.018921375274658203\n",
      "CPU times: user 26.3 s, sys: 2.61 s, total: 28.9 s\n",
      "Wall time: 22.4 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = LinearModel(784,10,verbose = False).to(gpu)\n",
    "model = torch.nn.DataParallel(model)\n",
    "\n",
    "#Each batch is split into number of gpus and data is scattered. Use verbose = True to verify parallel processing\n",
    "dataloader = DataLoader(train_ds,batch_size=args.batch)\n",
    "optimizer = torch.optim.Adam(params = model.parameters(), lr=args.lr)\n",
    "\n",
    "%time train(model, optimizer, dataloader, gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [00:02<00:00, 241.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7. 2. 1. 0. 4. 1. 4. 9. 6. 9.] [7. 2. 1. 0. 4. 1. 4. 9. 5. 9.]\n",
      "validation loss is 0.18366036267280578\n",
      "validation accuracy is 0.9409\n",
      "CPU times: user 2.89 s, sys: 344 ms, total: 3.23 s\n",
      "Wall time: 2.59 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "eval_dataloader = dataloader = DataLoader(test_ds, batch_size=args.batch)\n",
    "%time evaluate(model,eval_dataloader, gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Higher batch size\n",
    "Even for higher batch sizes, it's still slower than single GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 11/938 [00:00<00:09, 100.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:09<00:00, 102.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss at epoch 0 is 0.05216124653816223\n",
      "CPU times: user 10 s, sys: 813 ms, total: 10.9 s\n",
      "Wall time: 9.15 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Batch size can be increased to take advantage of the parallel processing\n",
    "dataloader = DataLoader(train_ds,batch_size=args.batch *4)\n",
    "#increase the lr for high batch size. (Provide proof for this)\n",
    "optimizer = torch.optim.Adam(params = model.parameters(), lr=args.lr * 4)\n",
    "\n",
    "%time train(model, optimizer, dataloader, gpu)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
