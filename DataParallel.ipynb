{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import DataParallel, Linear\n",
    "import torchvision\n",
    "from torch.utils.data.dataset import Dataset\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "import numpy as np\n",
    "import  matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load MNIST Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9912422 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9920512it [00:00, 14241615.71it/s]                           \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST_data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "32768it [00:00, 211290.46it/s]           \n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Extracting ./MNIST_data/MNIST/raw/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1654784it [00:00, 3741726.62it/s]                           \n",
      "8192it [00:00, 82859.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./MNIST_data/MNIST/raw/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Extracting ./MNIST_data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n",
      "Processing...\n",
      "Done!\n",
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: ./MNIST_data\n",
      "    Split: Train\n"
     ]
    }
   ],
   "source": [
    "mnist_train = torchvision.datasets.MNIST(root = './MNIST_data',train=True,download=True)\n",
    "mnist_train\n",
    "\n",
    "#A dataset returning pil image and label for each __getitem__ call\n",
    "print(mnist_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x1440 with 7 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize = (12,20))\n",
    "count = 7\n",
    "for i in range(count):\n",
    "    plt.subplot(1,count,i+1)\n",
    "    index = np.random.randint(0,len(mnist_train),(1,))[0]\n",
    "    im_array = np.asarray(mnist_train[index][0])\n",
    "    label = mnist_train[index][1]\n",
    "    imshow(im_array,cmap='gray',)\n",
    "    plt.title(str(index) + ' label:'+str(label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Images to array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(Dataset):\n",
    "    def __init__(self, mnist_dataset):\n",
    "        super(MyDataset,self).__init__()\n",
    "        self.mnist_dataset = mnist_dataset\n",
    "    def __getitem__(self, index):\n",
    "        item = self.mnist_dataset[index]\n",
    "        image = item[0]\n",
    "        label = item[1]\n",
    "        image_array = np.array(image,dtype = np.float32).reshape((-1))/255\n",
    "        return image_array, label\n",
    "    def __len__(self):\n",
    "        return len(self.mnist_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784,) 5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.        , 0.        , 0.        , 0.19215687, 0.93333334,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.9843137 , 0.3647059 ,\n",
       "        0.32156864, 0.32156864, 0.21960784, 0.15294118, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.07058824, 0.85882354, 0.99215686, 0.99215686,\n",
       "        0.99215686, 0.99215686, 0.99215686, 0.7764706 , 0.7137255 ,\n",
       "        0.96862745, 0.94509804, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ],\n",
       "       dtype=float32), 5)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ds = MyDataset(mnist_train)\n",
    "print(train_ds[0][0].shape,train_ds[0][1])\n",
    "train_ds[0][0][200:250],train_ds[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(batch=16, epochs=1, lr=0.001)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import argparse\n",
    "args = argparse.Namespace(\n",
    "    batch = 16,\n",
    "    lr = 0.001,\n",
    "    epochs =1\n",
    ")\n",
    "args"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearModel(torch.nn.Module):\n",
    "    def __init__(self, input_size, output_size, verbose = False):\n",
    "        super(LinearModel,self).__init__()\n",
    "        self.fc1 = torch.nn.Linear(input_size,64)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "        self.fc2 = torch.nn.Linear(64,output_size)\n",
    "        self.verbose = verbose\n",
    "    def forward(self, X):\n",
    "        \n",
    "        if self.verbose:\n",
    "            print('X shape = {}, current cuda device = {}' \\\n",
    "                  .format(X.shape,torch.cuda.current_device() if torch.cuda.is_available() else 'NAN'))\n",
    "        return self.fc2(self.relu(self.fc1(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape = torch.Size([784]), current cuda device = 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([-0.0945,  0.0790, -0.2225, -0.1946,  0.0569,  0.0140, -0.0683,  0.0222,\n",
       "        -0.0640, -0.0826], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = LinearModel(784,10,True)\n",
    "m(torch.Tensor(train_ds[0][0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(train_ds, batch_size=args.batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]]), tensor([5, 0, 4, 1, 9, 2, 1, 3, 1, 4, 3, 5, 3, 6, 1, 7])]\n"
     ]
    }
   ],
   "source": [
    "#converts arrays into tensor and creates batches\n",
    "for data in dataloader:\n",
    "    print(data)\n",
    "    #print(model(data[0]))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def train(model, optimizer, dataloader, device):\n",
    "    model.train()\n",
    "    print('using device',device)\n",
    "    losses = []\n",
    "    for epoch in range(args.epochs):\n",
    "        for x,y in tqdm(dataloader, position=0):\n",
    "            optimizer.zero_grad()\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "            yhat = model(x)\n",
    "            \n",
    "            loss = torch.nn.CrossEntropyLoss()(yhat, y)\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            losses.append(loss.item())\n",
    "            \n",
    "        print ('loss at epoch {} is {}'.format(epoch, losses[-1]))\n",
    "        for param in model.parameters():\n",
    "            print(param)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearModel(784,10)\n",
    "optimizer = torch.optim.Adam(params = model.parameters(), lr=args.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/3750 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device cpu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3750/3750 [00:18<00:00, 198.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss at epoch 0 is 0.018809974193572998\n",
      "Parameter containing:\n",
      "tensor([[-0.0282,  0.0239,  0.0053,  ..., -0.0080, -0.0225,  0.0338],\n",
      "        [-0.0121, -0.0017,  0.0047,  ..., -0.0148,  0.0015,  0.0313],\n",
      "        [ 0.0124,  0.0029, -0.0067,  ...,  0.0352, -0.0226, -0.0337],\n",
      "        ...,\n",
      "        [ 0.0127,  0.0104, -0.0105,  ...,  0.0155, -0.0187, -0.0217],\n",
      "        [-0.0350, -0.0055,  0.0135,  ...,  0.0355,  0.0095, -0.0082],\n",
      "        [ 0.0154,  0.0283,  0.0326,  ..., -0.0162, -0.0079, -0.0212]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0768, -0.0854, -0.0778,  0.0919,  0.0030,  0.2499, -0.1261, -0.0618,\n",
      "         0.0997, -0.0397,  0.0349, -0.1766,  0.1634,  0.0301,  0.1412,  0.0241,\n",
      "         0.2256,  0.1115, -0.0461,  0.0187, -0.1539,  0.0270,  0.0043, -0.0691,\n",
      "         0.0558,  0.0656, -0.0333,  0.0047, -0.1608, -0.0123, -0.0189,  0.0366,\n",
      "        -0.0263, -0.0634, -0.0687,  0.1254, -0.0778, -0.0655,  0.0036, -0.0768,\n",
      "         0.2181, -0.0484,  0.0725,  0.1896,  0.0620,  0.0759,  0.0658, -0.1001,\n",
      "        -0.0912,  0.1082,  0.2120,  0.1291,  0.1195,  0.0498,  0.0748, -0.0086,\n",
      "         0.0140, -0.0577, -0.0891, -0.0784,  0.1577,  0.2408,  0.1862,  0.1976],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 1.4767e-01, -2.7117e-01, -1.0911e-01, -2.7804e-01,  2.6849e-02,\n",
      "         -2.5308e-01, -1.1974e-01, -9.6400e-02, -2.4804e-01,  1.1439e-01,\n",
      "         -2.9265e-02,  1.4620e-01,  6.0227e-02, -2.6215e-01, -2.4628e-01,\n",
      "         -2.4239e-01, -5.1172e-01,  1.4791e-01, -2.5573e-02, -1.3999e-01,\n",
      "          1.2715e-01, -1.7078e-01, -2.9923e-01,  8.8900e-02, -4.6670e-02,\n",
      "          1.7066e-01,  2.8121e-02, -3.0134e-02,  1.2222e-01, -9.3010e-02,\n",
      "         -2.4413e-02, -5.6771e-02,  2.5130e-02, -8.1660e-02,  1.2897e-01,\n",
      "         -1.2427e-02, -5.5425e-02,  2.9515e-01,  1.2953e-01, -5.3375e-02,\n",
      "          2.9317e-02,  7.7344e-02,  4.7215e-02,  1.1144e-01, -6.0895e-02,\n",
      "          4.7420e-02,  8.1303e-02,  6.8513e-02, -2.2388e-01, -2.7944e-01,\n",
      "         -1.9478e-02,  1.3802e-01,  1.0074e-01,  9.3885e-02, -7.8590e-04,\n",
      "          1.3756e-01, -1.8224e-01,  4.2141e-02,  4.3370e-03,  3.2695e-01,\n",
      "          1.3052e-01, -3.5934e-02, -3.8963e-01, -4.2951e-02],\n",
      "        [-2.0302e-01,  6.9948e-02, -1.2448e-01, -1.7159e-01,  4.9494e-03,\n",
      "         -7.6781e-02,  2.3680e-01, -1.6479e-01, -1.3375e-01, -1.4036e-01,\n",
      "         -2.0802e-01, -3.2671e-01, -2.3578e-01, -1.7361e-01,  1.8647e-01,\n",
      "          1.1469e-01,  1.9831e-01, -1.7252e-01, -2.9106e-01,  9.8673e-02,\n",
      "         -2.4759e-01,  2.3094e-01, -1.5950e-01, -2.8781e-01,  1.4074e-01,\n",
      "         -2.0424e-01,  1.2067e-01, -2.7381e-02, -2.2157e-01,  4.6913e-02,\n",
      "          2.6863e-01,  2.3547e-01, -4.3441e-02, -1.0984e-01, -2.2897e-01,\n",
      "         -2.6085e-01, -6.3600e-02,  7.9994e-02, -3.1265e-01, -3.0106e-01,\n",
      "          2.3976e-01,  3.2798e-02,  2.5292e-01, -2.1031e-01, -4.7602e-02,\n",
      "         -2.0350e-01, -2.3424e-01,  1.2722e-01, -1.2267e-01, -9.3950e-02,\n",
      "          3.7831e-01, -5.2347e-02,  2.6684e-02, -3.1738e-01, -4.5368e-01,\n",
      "         -3.8164e-01,  2.0534e-01, -2.3991e-01,  1.6834e-01, -8.4688e-02,\n",
      "         -8.3708e-02,  1.3199e-01,  2.0765e-01,  1.3984e-01],\n",
      "        [ 2.0141e-01,  1.7789e-01,  1.1883e-01, -2.0522e-01,  3.3884e-02,\n",
      "          4.1474e-02, -7.6115e-02, -4.3952e-01,  2.7186e-01, -4.1517e-03,\n",
      "         -5.8616e-02,  6.0090e-02,  2.2326e-01, -1.1545e-01, -2.5293e-01,\n",
      "         -3.4046e-02,  9.1185e-02,  1.4642e-01,  8.2030e-02,  1.3173e-01,\n",
      "          6.0263e-02,  2.8193e-01,  1.0873e-01, -4.3562e-02,  1.6785e-01,\n",
      "          3.3319e-01, -3.4433e-02, -8.7558e-02, -7.4952e-03, -1.0165e-01,\n",
      "         -8.4337e-02,  2.4680e-01, -6.1762e-02, -9.8698e-02,  1.3414e-01,\n",
      "         -2.6806e-01, -2.0446e-01,  7.5223e-02, -1.8287e-01,  1.6233e-01,\n",
      "         -7.3433e-01, -4.6830e-02,  1.7610e-01, -2.1985e-02,  6.8110e-03,\n",
      "          2.7601e-01, -5.6729e-03,  1.1175e-01,  1.5813e-01,  1.5282e-01,\n",
      "         -1.8530e-01,  6.8963e-02, -8.0007e-02,  2.1445e-01, -2.1029e-02,\n",
      "         -2.3598e-01, -8.3135e-02,  8.4610e-02,  2.0099e-01, -9.2642e-02,\n",
      "         -1.6347e-01,  1.9538e-01, -1.7481e-01, -3.7118e-01],\n",
      "        [ 1.5123e-01,  1.7966e-01,  7.0789e-02, -3.4415e-01, -5.1345e-02,\n",
      "         -2.1600e-01, -2.8110e-02, -2.8267e-02, -2.2227e-01,  1.2043e-01,\n",
      "          4.8507e-02, -1.1026e-01, -1.8198e-01,  1.8293e-01,  6.7335e-04,\n",
      "          1.7919e-01, -5.4012e-02, -2.0469e-01,  3.2603e-02, -8.4618e-02,\n",
      "          1.2528e-01,  2.6459e-01,  1.5467e-01, -2.0705e-01, -2.5890e-01,\n",
      "         -1.5167e-01,  1.0929e-01, -9.5328e-02,  1.3941e-01,  2.2297e-01,\n",
      "         -5.0167e-01,  9.4314e-02, -1.3547e-01, -2.0721e-01,  2.1113e-01,\n",
      "         -1.3824e-01, -5.6379e-02, -3.6155e-01,  1.0273e-01, -8.7840e-03,\n",
      "         -1.5350e-01,  4.0543e-02, -6.6501e-02, -1.8455e-01,  8.9238e-02,\n",
      "         -1.1870e-01,  1.2054e-01,  9.1998e-02,  1.2676e-01, -1.7113e-01,\n",
      "          8.1768e-02,  8.9088e-04, -2.4697e-01,  6.3433e-02, -1.2746e-01,\n",
      "         -1.9079e-01,  1.5614e-01,  5.4581e-02, -1.8810e-01, -3.6073e-01,\n",
      "         -4.3481e-02, -1.2159e-01, -7.2716e-03,  1.1232e-01],\n",
      "        [-2.7818e-01,  1.6720e-01, -7.4545e-02,  1.3820e-01, -3.0046e-02,\n",
      "          2.5401e-01,  1.6510e-01, -1.4071e-02,  2.8277e-01, -2.7905e-01,\n",
      "          2.0606e-01,  6.4462e-02,  1.6781e-01,  1.3573e-01,  2.7604e-01,\n",
      "         -2.3620e-01, -4.1042e-01,  1.2044e-01,  1.3946e-02,  2.9489e-02,\n",
      "          5.3276e-02, -7.9624e-02,  3.6457e-02,  1.6169e-01, -1.8957e-01,\n",
      "         -3.2561e-01, -3.3703e-01, -4.8996e-02, -3.0772e-01, -2.8247e-01,\n",
      "          3.2420e-02, -3.9871e-01, -1.8424e-02,  1.3958e-01, -2.2580e-01,\n",
      "         -1.5467e-04, -2.0218e-01,  1.9745e-01, -3.0228e-01, -1.5549e-02,\n",
      "         -2.2415e-01, -1.0659e-02, -8.2123e-02, -1.1762e-01,  7.9142e-02,\n",
      "         -2.5062e-01,  1.4803e-01, -4.1040e-01,  1.2377e-01, -1.2939e-01,\n",
      "         -1.9286e-01, -2.7395e-01,  1.6982e-01,  1.4185e-01, -2.2506e-02,\n",
      "          6.0097e-02,  1.5333e-01, -8.6684e-02, -3.0890e-01, -4.1248e-02,\n",
      "         -2.7756e-01, -2.3218e-01,  2.0917e-01,  1.1168e-01],\n",
      "        [-1.2437e-01, -2.8677e-01,  7.8639e-02,  7.8114e-02,  9.6349e-02,\n",
      "          3.3240e-01, -2.4891e-01,  1.8757e-01,  2.1181e-01,  1.4255e-01,\n",
      "          1.2837e-02, -2.1216e-01,  8.5279e-02,  6.5463e-02, -2.7695e-01,\n",
      "          1.0135e-01,  2.5285e-01,  6.7232e-02, -1.0923e-01,  3.4950e-02,\n",
      "         -1.1321e-01,  1.5331e-02, -8.0160e-02, -1.1077e-01, -1.6627e-01,\n",
      "          2.1323e-01,  9.3584e-03, -1.1193e-01,  1.4133e-01, -8.3218e-02,\n",
      "         -1.1300e-01, -3.1651e-01, -9.7896e-02, -2.0419e-01, -2.4945e-02,\n",
      "          4.7842e-02, -1.4989e-01, -3.8273e-01, -5.0159e-02, -4.3869e-01,\n",
      "          4.1995e-01, -1.1005e-01, -8.2007e-01,  2.2140e-01, -1.1655e-01,\n",
      "         -6.0237e-02, -2.5004e-01, -1.2994e-02, -3.8155e-02, -5.2695e-02,\n",
      "          1.9128e-01,  1.9073e-01, -1.3338e-01, -7.6631e-02,  1.6737e-01,\n",
      "          1.4807e-01,  1.3981e-01,  1.5656e-01, -1.0336e-01, -3.5850e-01,\n",
      "          2.1601e-01,  4.7176e-01,  2.1467e-03,  1.3503e-01],\n",
      "        [ 9.9539e-02,  7.6046e-02, -2.0731e-01,  1.1748e-01,  8.9371e-02,\n",
      "         -2.4588e-01, -6.1330e-02,  4.5489e-02, -2.7590e-01, -1.5999e-02,\n",
      "         -3.5667e-01, -1.5572e-01, -1.7959e-01, -4.5913e-01, -2.9100e-01,\n",
      "          3.4115e-04, -1.1380e-01,  1.7716e-01,  1.1497e-01,  1.8646e-01,\n",
      "          1.3010e-01, -3.6632e-01,  2.0285e-01,  2.1441e-01,  2.9032e-02,\n",
      "         -1.9043e-01, -2.2667e-01,  6.3115e-02, -1.2636e-01, -3.9389e-01,\n",
      "          2.5440e-01, -4.5827e-01,  5.8288e-02, -2.1730e-01, -2.0032e-01,\n",
      "          7.7699e-02,  1.3914e-01, -7.9425e-02, -1.9409e-01, -2.4959e-01,\n",
      "          1.2159e-01, -4.3190e-02, -7.7567e-02, -1.0009e-01, -4.1718e-01,\n",
      "         -1.5040e-01, -1.3085e-01, -2.2360e-01, -1.0357e-01,  2.2933e-01,\n",
      "          5.2219e-02,  1.6879e-01,  2.3145e-01,  1.8554e-01, -2.6321e-01,\n",
      "         -7.3644e-02,  8.5217e-02,  1.8946e-01, -1.2856e-01,  1.2918e-02,\n",
      "         -1.8471e-01, -3.0209e-01,  1.4010e-01, -2.2021e-01],\n",
      "        [ 1.5024e-01,  1.5637e-01, -2.7024e-01, -1.6786e-01, -1.7356e-02,\n",
      "          2.8091e-01,  7.8978e-02, -3.9400e-01, -3.9007e-01, -3.9877e-01,\n",
      "          1.0313e-01, -2.0952e-01,  2.0279e-02,  1.2634e-01,  1.5211e-01,\n",
      "         -9.2728e-03,  2.6297e-02, -1.2371e-01, -2.6368e-01, -3.9975e-01,\n",
      "         -6.0992e-02,  2.5939e-01,  1.5634e-01, -3.2760e-03,  1.7685e-01,\n",
      "          2.5299e-01,  1.4938e-01, -7.2077e-02, -3.5562e-01,  1.6176e-01,\n",
      "         -2.5544e-01,  1.1870e-01,  4.4900e-02,  3.5638e-02, -2.3934e-01,\n",
      "          1.4854e-01,  1.5592e-01,  2.4439e-02,  6.8408e-02,  1.5194e-01,\n",
      "          8.8301e-02, -1.1553e-01, -2.8685e-02,  2.8387e-01,  1.4356e-01,\n",
      "         -2.3749e-03,  1.8919e-01, -1.4737e-01,  1.3146e-01, -9.3426e-03,\n",
      "         -1.2177e-01, -3.2894e-01,  7.7844e-02, -2.3234e-01,  4.1387e-02,\n",
      "          1.4601e-02, -3.5667e-01, -3.2073e-01, -1.2083e-01, -1.1637e-02,\n",
      "          2.5196e-01, -2.8027e-01, -1.6464e-01,  1.1362e-01],\n",
      "        [ 1.7365e-03,  1.0526e-01,  9.1166e-02,  2.0799e-02, -3.3222e-02,\n",
      "         -2.2335e-01,  1.9109e-01,  1.9411e-01, -1.6123e-01, -6.4883e-02,\n",
      "          8.7188e-02,  1.7395e-01, -5.7752e-01,  1.0267e-01, -2.2943e-01,\n",
      "          4.7548e-02, -1.5299e-01, -1.2127e-01, -2.0428e-01,  1.5599e-01,\n",
      "         -7.1941e-04, -1.1944e-01, -6.6354e-02,  1.5351e-01, -4.4728e-03,\n",
      "          7.5741e-04,  1.6205e-01, -4.6537e-02,  9.4376e-02,  3.7792e-02,\n",
      "          7.1462e-02, -9.9402e-02,  4.0809e-02,  1.0108e-01, -7.0923e-02,\n",
      "         -5.7959e-02,  1.2399e-01, -8.6865e-02, -1.7566e-01, -4.0136e-02,\n",
      "         -1.3376e-01,  8.5213e-02, -1.2397e-01, -2.0113e-01, -5.8522e-02,\n",
      "         -1.5095e-01, -3.4636e-01,  1.3167e-01,  1.1733e-01, -9.0269e-02,\n",
      "         -3.5226e-01, -6.1605e-02, -7.7918e-02, -2.3062e-01,  8.5651e-02,\n",
      "          1.5334e-01,  1.6458e-01,  7.3679e-02,  2.0137e-01, -3.0495e-01,\n",
      "         -3.9527e-01, -4.8232e-01, -9.8846e-02,  2.2637e-03],\n",
      "        [ 1.1185e-01, -3.0345e-01, -1.9110e-02,  5.8442e-02, -1.0563e-01,\n",
      "         -3.8173e-01, -2.7269e-01,  9.4789e-02, -4.0424e-02, -3.7992e-02,\n",
      "          1.3859e-01,  1.6165e-01,  1.8946e-01,  8.9390e-02,  2.4622e-01,\n",
      "          1.3538e-01, -1.0480e-01, -2.5084e-01,  9.3102e-02, -8.5390e-02,\n",
      "          1.3933e-01, -5.8889e-01, -1.8366e-01, -1.4755e-01, -5.6684e-01,\n",
      "         -5.1873e-01,  1.3848e-02, -8.9206e-02, -4.0264e-02, -7.7104e-02,\n",
      "         -1.0338e-01,  1.6636e-01, -8.7208e-02,  1.8523e-01, -1.6902e-01,\n",
      "          1.6660e-01,  2.4221e-02, -3.0390e-02,  1.3924e-01,  8.6826e-02,\n",
      "          7.4721e-02,  4.2602e-02,  9.0050e-02, -3.9687e-02,  2.4554e-01,\n",
      "         -2.0860e-01,  4.1104e-02, -1.7068e-01, -1.0272e-01,  8.3934e-02,\n",
      "         -3.7231e-01, -2.4400e-01,  6.9282e-02, -4.2770e-01,  1.1164e-01,\n",
      "         -2.0104e-01,  5.5448e-02, -2.6444e-02,  5.0547e-03,  1.9757e-01,\n",
      "          1.6322e-01, -2.5389e-01, -1.5714e-01, -2.6362e-03]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.1294,  0.1531, -0.0716,  0.0281,  0.0928,  0.1343, -0.1050,  0.0320,\n",
      "        -0.1033, -0.0541], requires_grad=True)\n",
      "CPU times: user 23.5 s, sys: 16.6 s, total: 40.1 s\n",
      "Wall time: 19 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cpu = torch.device('cpu')\n",
    "train(model,optimizer,dataloader, cpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/3750 [00:00<10:02,  6.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3750/3750 [00:10<00:00, 343.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss at epoch 0 is 0.02160853147506714\n",
      "Parameter containing:\n",
      "tensor([[ 0.0144, -0.0056,  0.0202,  ...,  0.0184,  0.0288,  0.0158],\n",
      "        [-0.0348, -0.0038, -0.0159,  ..., -0.0275, -0.0320, -0.0029],\n",
      "        [ 0.0001,  0.0311,  0.0231,  ..., -0.0039, -0.0227, -0.0015],\n",
      "        ...,\n",
      "        [ 0.0031,  0.0340,  0.0298,  ...,  0.0060, -0.0018, -0.0222],\n",
      "        [-0.0172,  0.0206,  0.0066,  ...,  0.0064, -0.0346, -0.0296],\n",
      "        [ 0.0290, -0.0145, -0.0155,  ...,  0.0103,  0.0070, -0.0222]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.1380,  0.0642, -0.0092,  0.0046,  0.0198,  0.2525,  0.1475,  0.0672,\n",
      "         0.0433,  0.1507, -0.0757, -0.0282, -0.0282, -0.1713, -0.0778,  0.1163,\n",
      "         0.1871,  0.0630,  0.1163,  0.3615, -0.1441, -0.1001, -0.0532,  0.0397,\n",
      "         0.0834, -0.0422,  0.0019,  0.1109,  0.1919, -0.1069, -0.0486, -0.1045,\n",
      "         0.0707, -0.0509, -0.1222, -0.0036,  0.1227, -0.1264,  0.0935, -0.0079,\n",
      "        -0.0700,  0.1036, -0.1140, -0.0152,  0.0278,  0.0792, -0.0028,  0.1548,\n",
      "         0.0417, -0.0208,  0.1633,  0.0427,  0.0528,  0.1302,  0.0380,  0.1254,\n",
      "        -0.0270, -0.0073,  0.1415,  0.2007, -0.0183, -0.0237,  0.1099, -0.0322],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 1.4297e-01, -9.5855e-02,  7.8574e-02, -8.8920e-02, -2.7434e-01,\n",
      "         -1.8971e-03, -2.6876e-01,  2.4011e-01, -1.9212e-01, -5.0588e-01,\n",
      "         -2.8851e-01, -2.0600e-02, -3.9921e-02, -1.2193e-01, -1.4514e-01,\n",
      "         -3.3839e-01, -1.9043e-01,  1.3911e-01, -1.7712e-01,  4.2271e-03,\n",
      "          1.8101e-01, -1.1430e-01,  1.3879e-02, -2.6663e-01,  6.1481e-02,\n",
      "         -2.4663e-02,  2.0906e-01,  1.1769e-01,  2.3396e-01,  1.5780e-01,\n",
      "         -1.7472e-01,  2.0068e-01,  1.1371e-01,  1.0477e-01,  1.7603e-03,\n",
      "          1.4472e-01, -7.9765e-03,  8.9084e-02, -2.1776e-01,  6.1265e-02,\n",
      "          4.3383e-02, -5.9277e-01, -1.2967e-02,  8.2476e-02,  2.3963e-01,\n",
      "         -1.3690e-01, -3.4457e-01, -1.4580e-01, -3.6391e-01, -4.9263e-02,\n",
      "         -7.7782e-03, -2.5752e-01, -3.5051e-01,  6.5740e-02, -2.3868e-01,\n",
      "         -1.3987e-01, -1.4272e-01,  2.4994e-01, -8.7360e-02, -6.5488e-02,\n",
      "         -6.3388e-02, -1.8404e-02,  8.1563e-02, -3.2718e-01],\n",
      "        [-2.1421e-01,  8.4371e-02, -5.3597e-02,  5.9007e-02, -1.2176e-01,\n",
      "          4.6339e-01,  9.3814e-02, -4.2401e-03, -9.5973e-02,  3.1002e-02,\n",
      "          1.4276e-01,  7.8499e-02,  1.3664e-01,  1.6601e-02, -2.1489e-01,\n",
      "          2.6680e-01, -1.2908e-01, -6.3204e-02,  2.7935e-01, -4.2303e-02,\n",
      "          1.2336e-01,  1.2821e-01,  1.0171e-01,  2.2413e-01, -2.2747e-01,\n",
      "          4.0358e-02,  2.1369e-01, -2.7825e-01, -1.8070e-01,  2.7608e-02,\n",
      "          2.2643e-01,  1.4349e-02, -3.3711e-01, -1.4781e-01,  1.0365e-01,\n",
      "         -2.3380e-01,  4.4614e-02, -1.6940e-01, -7.1053e-02, -2.7325e-01,\n",
      "         -1.9405e-01,  2.7903e-01, -2.5898e-01, -4.0754e-02, -3.3800e-01,\n",
      "         -2.3027e-01, -9.1413e-03,  7.1995e-02,  9.0071e-02, -7.4006e-02,\n",
      "         -3.0721e-01,  2.7269e-01,  1.7463e-02, -2.2683e-01, -1.9728e-01,\n",
      "          2.9577e-01, -1.6496e-01, -2.9669e-01,  1.2742e-01, -2.3373e-01,\n",
      "         -1.7034e-01, -3.4471e-01,  1.1040e-03,  1.3273e-01],\n",
      "        [ 1.1144e-01, -4.5606e-02,  2.3273e-02, -1.3864e-01, -2.1525e-01,\n",
      "         -3.2012e-01, -3.1388e-01,  1.8907e-01, -9.8850e-02, -2.2908e-01,\n",
      "          9.1115e-02,  8.6846e-02,  1.8834e-01,  1.0423e-01,  4.1622e-02,\n",
      "          4.1063e-02, -7.6462e-01,  2.6692e-01, -6.2779e-02, -3.0525e-02,\n",
      "         -2.3157e-02,  5.4811e-02, -4.9993e-01,  2.0949e-01,  7.8205e-02,\n",
      "         -2.8862e-02, -5.3003e-02, -5.6203e-02,  1.0425e-01, -8.3545e-02,\n",
      "          1.1604e-01,  2.4420e-01, -1.1146e-01, -3.0922e-01, -8.3787e-02,\n",
      "         -2.4563e-01, -2.1358e-01, -2.1279e-01,  2.2912e-01,  2.4052e-01,\n",
      "          1.9979e-01, -2.8537e-01, -1.2375e-01, -2.8548e-01, -2.5348e-02,\n",
      "         -1.1424e-01, -4.9066e-02,  5.1928e-02,  1.1238e-02,  6.7626e-02,\n",
      "          2.4041e-01,  1.2994e-01, -3.0497e-01,  5.2419e-04, -1.6965e-01,\n",
      "         -2.7319e-01,  1.3801e-01, -2.3503e-02,  1.2857e-01, -1.3101e-01,\n",
      "          8.3877e-02, -1.8113e-01,  1.4230e-01,  2.4528e-01],\n",
      "        [-1.6024e-01,  1.6932e-01,  2.4253e-04,  2.4719e-01,  4.9488e-02,\n",
      "         -5.1773e-01,  2.4255e-01, -1.1848e-01, -6.1759e-02,  6.1884e-02,\n",
      "          2.0916e-01,  2.4922e-02,  4.6407e-02,  1.9806e-02,  1.8544e-01,\n",
      "          7.6301e-02, -4.1460e-01,  1.8202e-01, -1.6455e-01, -2.4364e-01,\n",
      "         -2.2457e-02, -4.7903e-02, -2.0980e-01,  2.2697e-01,  1.9022e-01,\n",
      "          6.9532e-02, -1.1014e-01, -1.7552e-01, -2.8269e-03,  2.1090e-01,\n",
      "         -2.4202e-01, -3.1641e-02, -1.7579e-01,  1.2868e-01, -3.1753e-01,\n",
      "         -2.1387e-01, -2.9361e-01, -8.5181e-03,  8.0836e-04,  9.4337e-02,\n",
      "         -3.7892e-02,  1.8157e-01, -1.4978e-01,  1.7765e-01,  1.1783e-01,\n",
      "         -3.7168e-02,  1.2802e-01, -2.1919e-01, -2.9268e-02, -5.8876e-02,\n",
      "         -1.0296e-01, -1.5171e-01,  2.0886e-01, -2.8362e-01, -1.0143e-01,\n",
      "          1.0018e-01,  1.1016e-01,  8.9531e-02, -1.8696e-01, -4.4953e-01,\n",
      "         -3.6501e-02, -1.2685e-01, -7.4199e-02, -6.9672e-03],\n",
      "        [-7.3463e-02,  1.4131e-01, -8.8365e-02,  2.0471e-01,  2.4856e-01,\n",
      "          1.4988e-01,  9.5342e-02, -2.5239e-01, -1.1607e-01,  2.2697e-01,\n",
      "         -1.1229e-01, -2.2326e-02, -5.3725e-02, -1.1207e-01,  3.7796e-02,\n",
      "         -1.7802e-01,  6.4909e-02, -1.7845e-01, -1.8026e-01,  1.1936e-01,\n",
      "         -4.5565e-01,  5.4320e-02,  1.0766e-01, -1.6523e-01, -2.9369e-01,\n",
      "         -1.2981e-01, -2.9995e-01,  2.1456e-01,  1.1832e-01, -2.5204e-01,\n",
      "         -2.2492e-02,  1.7630e-01, -4.7018e-02, -1.6816e-01,  8.3087e-02,\n",
      "         -1.4582e-02,  1.4691e-01,  1.5980e-01,  2.2801e-01, -4.5165e-01,\n",
      "         -4.0854e-01, -3.7889e-04,  1.4987e-01, -5.4206e-01, -2.1055e-01,\n",
      "         -5.0013e-02,  2.1287e-01,  7.8292e-02, -2.2473e-01, -3.4661e-02,\n",
      "          1.3768e-01, -7.1563e-02,  1.1747e-01,  1.1600e-01,  1.5717e-01,\n",
      "         -3.3634e-01, -2.1178e-01, -2.7938e-01, -1.6310e-01,  2.6905e-01,\n",
      "         -2.7899e-03, -1.5648e-02,  1.3277e-01, -2.1290e-02],\n",
      "        [ 1.4859e-01, -3.6546e-01, -9.1095e-03, -4.9271e-01,  1.7409e-01,\n",
      "          3.1089e-01,  3.6477e-01,  1.1212e-02, -4.1899e-01,  1.6497e-01,\n",
      "         -1.0316e-01,  9.5860e-02, -3.4017e-01, -2.4395e-01,  1.2446e-01,\n",
      "          1.1592e-01,  4.5248e-01,  1.1484e-01,  1.7950e-01,  2.8275e-01,\n",
      "         -1.7901e-01, -1.6303e-01, -1.8755e-01, -4.2633e-02,  1.2915e-01,\n",
      "         -4.1182e-03,  4.7572e-02,  4.1619e-02,  7.5931e-02, -9.0722e-02,\n",
      "         -1.9829e-01, -1.9407e-01,  1.1896e-01,  2.0359e-01, -9.3810e-02,\n",
      "         -2.9353e-01,  6.7303e-02, -5.1666e-03,  3.8347e-02,  3.0996e-02,\n",
      "         -2.7189e-03,  2.4787e-01, -2.0895e-01,  1.0972e-01,  1.4999e-01,\n",
      "          8.2767e-02, -1.7743e-01,  1.1191e-01,  8.7993e-02, -8.4681e-02,\n",
      "         -1.9171e-01, -5.2789e-01,  1.0967e-01,  1.3738e-02, -1.3507e-01,\n",
      "          9.7304e-02,  9.2043e-02, -2.0184e-02,  1.4620e-01,  2.0797e-01,\n",
      "          8.5222e-02, -1.2565e-01, -2.2237e-01, -2.5385e-01],\n",
      "        [ 1.1627e-01, -3.7220e-01,  3.8021e-02,  1.1099e-01,  7.1876e-02,\n",
      "         -1.0407e-01, -1.1592e-02,  1.6175e-01,  2.1794e-02, -3.1887e-01,\n",
      "         -2.2872e-01,  2.8333e-02, -4.1414e-01,  9.4877e-02, -1.6566e-01,\n",
      "         -6.4428e-02,  2.3469e-01, -1.4190e-01,  2.6903e-01, -3.2564e-01,\n",
      "         -1.1509e-01,  1.7764e-01,  1.7872e-01, -2.4689e-01, -3.3677e-01,\n",
      "         -7.0115e-03,  4.9511e-03,  2.7726e-02,  1.3224e-01,  8.5901e-02,\n",
      "          2.0620e-03,  1.0072e-01, -1.8587e-01,  2.8513e-02, -1.4477e-01,\n",
      "          1.3071e-01,  4.5881e-02, -1.4659e-01,  1.2428e-01, -4.1338e-01,\n",
      "          3.5341e-02, -3.5561e-01, -3.3948e-03,  3.5701e-01, -1.6098e-02,\n",
      "         -5.2197e-01,  1.2409e-01,  2.7431e-01, -4.8330e-01,  9.4802e-02,\n",
      "          7.4386e-03, -1.5294e-01, -4.5095e-01, -2.1295e-01,  1.4630e-01,\n",
      "         -5.4722e-01,  6.1679e-03, -1.9962e-01,  2.7017e-01,  7.6804e-02,\n",
      "          3.7883e-02,  6.9183e-02,  1.1831e-01, -1.3665e-01],\n",
      "        [-1.3260e-02,  1.8073e-01, -6.1174e-02,  1.1909e-01, -3.5226e-01,\n",
      "         -3.3424e-02, -3.3059e-01, -1.4075e-01,  1.7949e-01, -7.6150e-02,\n",
      "          1.7534e-01,  9.6747e-03,  2.0747e-01, -2.0503e-01, -2.3836e-01,\n",
      "         -2.6461e-01, -3.3054e-01,  1.8559e-02, -1.2062e-01,  2.6598e-01,\n",
      "         -1.4802e-01, -3.3073e-01, -2.1804e-01,  3.2050e-01,  2.1858e-01,\n",
      "          1.1033e-01, -1.8613e-01,  2.1199e-01, -9.4976e-02, -1.0656e-01,\n",
      "         -1.2097e-01, -3.8325e-01,  6.7725e-02, -7.0857e-02, -9.2765e-02,\n",
      "         -8.6638e-02, -9.5626e-02, -2.5424e-01, -3.2548e-01, -1.1627e-02,\n",
      "          1.4043e-01, -4.2712e-01,  1.1405e-01,  1.5610e-01, -2.8493e-03,\n",
      "          1.3426e-01, -1.3587e-01, -4.6869e-02,  1.8134e-01,  3.5013e-03,\n",
      "          1.4542e-01, -1.1919e-02,  2.5765e-02,  2.1104e-01,  8.0924e-02,\n",
      "          1.6304e-01, -3.1822e-01, -6.0047e-02, -2.8252e-01,  9.4920e-02,\n",
      "         -4.1539e-01,  1.7529e-01,  4.7185e-02,  2.0425e-01],\n",
      "        [-5.6460e-02, -8.7184e-02,  5.7231e-02, -1.1094e-01,  9.0391e-02,\n",
      "         -5.6700e-01, -4.9344e-01, -2.8961e-02, -1.8577e-01, -1.4987e-03,\n",
      "          1.3131e-01, -1.2194e-02,  5.4377e-02,  1.0769e-01,  1.5600e-01,\n",
      "          2.2115e-02, -1.5107e-01, -1.8922e-01, -6.3630e-02, -4.4699e-01,\n",
      "          1.3697e-01,  1.5488e-01,  6.3384e-02, -8.1427e-02, -1.1423e-01,\n",
      "         -5.7580e-02,  9.2956e-02,  2.5508e-02, -2.2466e-01, -2.4134e-02,\n",
      "         -5.1879e-02,  3.1716e-02,  1.1378e-01,  2.1023e-01,  1.8620e-01,\n",
      "         -2.2175e-01, -1.6961e-01,  2.0220e-01,  6.0731e-02, -8.8509e-02,\n",
      "          1.2561e-01, -1.8604e-01,  1.2377e-01, -9.4219e-02,  9.1686e-03,\n",
      "          4.2376e-02, -8.6877e-03,  4.6582e-02,  1.1444e-01, -1.2388e-01,\n",
      "         -5.0135e-01,  1.5614e-02,  8.4166e-02, -7.4092e-02, -2.9305e-01,\n",
      "         -4.0120e-01,  1.2475e-01, -1.3326e-01, -1.4174e-01,  3.2158e-02,\n",
      "          1.1215e-01,  5.3382e-02, -2.1968e-01,  9.3069e-02],\n",
      "        [-3.2476e-01,  1.4908e-01, -9.3843e-02, -4.6922e-02,  8.2056e-03,\n",
      "         -2.7498e-01,  6.4381e-02, -2.4969e-01,  1.9586e-01, -1.4369e-02,\n",
      "         -2.3841e-01, -1.7509e-02,  9.0917e-02,  2.1433e-01,  9.9057e-02,\n",
      "         -1.5734e-02,  2.2093e-01, -3.5164e-01, -4.7113e-01, -6.6531e-03,\n",
      "         -1.2917e-02,  2.0590e-01,  2.4841e-01, -3.9067e-01,  1.2062e-01,\n",
      "         -4.7611e-02, -2.7009e-01, -1.3544e-01, -1.5031e-01, -7.2386e-02,\n",
      "         -1.2981e-01,  1.7556e-01,  8.4646e-02, -1.4185e-02, -2.5437e-02,\n",
      "          1.8250e-01,  1.6092e-01, -5.2192e-02, -3.5095e-01,  1.8644e-01,\n",
      "         -6.4370e-02,  2.2869e-01,  1.0310e-01, -2.3462e-01, -9.6082e-02,\n",
      "          9.7314e-02, -1.5526e-01, -4.7484e-02,  7.1910e-02, -4.6766e-02,\n",
      "          1.0737e-01, -3.8804e-01, -2.6959e-03,  9.9712e-02,  1.6517e-01,\n",
      "          1.3391e-01, -1.8918e-01,  9.3029e-02,  2.5813e-03, -4.1272e-02,\n",
      "         -4.5757e-02, -6.2659e-02, -1.0681e-01, -3.0108e-01]], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0825,  0.1196,  0.0974,  0.0298, -0.0864,  0.1371, -0.1123,  0.1929,\n",
      "        -0.1915, -0.0814], device='cuda:0', requires_grad=True)\n",
      "CPU times: user 11 s, sys: 0 ns, total: 11 s\n",
      "Wall time: 11 s\n"
     ]
    }
   ],
   "source": [
    "gpu = torch.device('cuda')\n",
    "model = LinearModel(784,10)\n",
    "model = model.to(gpu)\n",
    "dataloader = DataLoader(train_ds,batch_size=args.batch)\n",
    "optimizer = torch.optim.Adam(params = model.parameters(), lr=args.lr)\n",
    "\n",
    "%time train(model, optimizer, dataloader, gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Higher batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/938 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:06<00:00, 153.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss at epoch 0 is 0.02466443181037903\n",
      "Parameter containing:\n",
      "tensor([[ 0.0144, -0.0056,  0.0202,  ...,  0.0184,  0.0288,  0.0158],\n",
      "        [-0.0348, -0.0038, -0.0159,  ..., -0.0275, -0.0320, -0.0029],\n",
      "        [ 0.0001,  0.0311,  0.0231,  ..., -0.0039, -0.0227, -0.0015],\n",
      "        ...,\n",
      "        [ 0.0031,  0.0340,  0.0298,  ...,  0.0060, -0.0018, -0.0222],\n",
      "        [-0.0172,  0.0206,  0.0066,  ...,  0.0064, -0.0346, -0.0296],\n",
      "        [ 0.0290, -0.0145, -0.0155,  ...,  0.0103,  0.0070, -0.0222]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.2082, -0.0493, -0.0092, -0.0659, -0.0102,  0.2911,  0.1645,  0.1115,\n",
      "         0.0175,  0.2169, -0.1462, -0.0282, -0.0393, -0.2371, -0.1923,  0.0631,\n",
      "         0.2444,  0.0855,  0.0938,  0.4658, -0.2426, -0.1398, -0.0628, -0.0367,\n",
      "         0.0546, -0.0422, -0.0458,  0.2201,  0.2209, -0.1406, -0.0745, -0.1477,\n",
      "         0.0722, -0.0770, -0.1561, -0.0244,  0.0923, -0.1770,  0.2482, -0.0263,\n",
      "        -0.1039,  0.0657, -0.1865, -0.0472,  0.0405,  0.1441, -0.0435,  0.1600,\n",
      "         0.0517, -0.0208,  0.2597,  0.0087,  0.0018,  0.2174,  0.0581,  0.1373,\n",
      "        -0.0224, -0.0782,  0.1881,  0.2760, -0.0062, -0.0199,  0.1781, -0.0896],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 2.7206e-01, -7.3809e-02,  7.8574e-02, -2.3268e-01, -4.3079e-01,\n",
      "         -1.1050e-01, -4.4731e-01,  2.3599e-01, -2.4243e-01, -7.0097e-01,\n",
      "         -3.8758e-01, -2.0600e-02, -7.7194e-03, -3.8994e-02, -3.9926e-01,\n",
      "         -4.4360e-01, -2.3557e-01,  2.1924e-01, -3.0466e-01,  1.3069e-02,\n",
      "          2.5880e-01, -1.4206e-01,  1.2230e-01, -5.2911e-01,  1.4683e-01,\n",
      "         -2.4663e-02,  2.2779e-01,  1.4570e-01,  2.0968e-01,  2.6109e-01,\n",
      "         -4.4663e-01,  2.6114e-01,  1.0228e-01,  1.5927e-01,  2.2832e-02,\n",
      "          2.6864e-01, -1.1036e-01,  2.8560e-02, -3.3357e-01,  1.2991e-01,\n",
      "         -1.3303e-02, -6.9671e-01,  2.8949e-02,  1.4604e-01,  2.7773e-01,\n",
      "         -2.0950e-01, -4.8162e-01, -1.8664e-01, -5.5103e-01, -4.9263e-02,\n",
      "          2.9580e-02, -2.8870e-01, -4.4824e-01,  8.2157e-02, -3.8387e-01,\n",
      "         -1.9319e-01, -6.3596e-02,  2.9166e-01, -3.2990e-01,  2.2124e-02,\n",
      "         -3.7486e-02,  3.6238e-02,  1.3885e-01, -2.9354e-01],\n",
      "        [-4.8650e-02,  1.1306e-01, -5.3597e-02,  1.3041e-01, -2.9487e-01,\n",
      "          6.6056e-01,  2.1337e-01,  1.2182e-01, -1.8867e-01,  2.3124e-02,\n",
      "          1.4028e-01,  7.8499e-02,  1.2693e-01,  3.6119e-02, -3.3422e-01,\n",
      "          2.1944e-01, -1.4529e-01, -2.1989e-02,  2.9126e-01, -6.8654e-03,\n",
      "          3.4296e-02,  1.3641e-01,  8.8669e-02,  2.0349e-01, -3.0503e-01,\n",
      "          4.0358e-02,  1.1624e-01, -2.1044e-01, -1.6531e-01, -1.2856e-01,\n",
      "          4.3941e-01, -1.2717e-01, -4.6521e-01, -2.7876e-01,  7.7473e-02,\n",
      "         -2.9002e-01, -4.2709e-02, -1.8947e-01, -1.0538e-01, -3.1496e-01,\n",
      "         -2.3697e-01,  2.0897e-01, -2.7702e-01, -3.9728e-01, -4.3804e-01,\n",
      "         -5.3346e-01,  1.3933e-01, -1.2617e-02, -9.6899e-03, -7.4006e-02,\n",
      "         -3.6774e-01,  2.7178e-01, -7.1656e-03, -2.1550e-01, -2.3027e-01,\n",
      "          3.1381e-01, -1.3074e-01, -3.6800e-01,  1.1017e-01, -3.4154e-01,\n",
      "         -1.6286e-01, -2.9170e-01,  2.5403e-01,  1.3496e-01],\n",
      "        [ 1.9099e-01, -1.2976e-01,  2.3273e-02, -3.4805e-02, -2.4097e-01,\n",
      "         -3.7605e-01, -5.0691e-01,  1.6465e-01, -1.3293e-01, -1.9602e-01,\n",
      "          1.9373e-01,  8.6846e-02,  2.2539e-01,  4.7141e-02, -7.9932e-02,\n",
      "          9.6656e-02, -9.0811e-01,  3.1403e-01, -2.4815e-01, -1.3719e-02,\n",
      "          8.2516e-02,  1.4759e-01, -7.6848e-01,  3.3061e-01,  4.4289e-02,\n",
      "         -2.8862e-02, -8.3399e-03, -1.7291e-01,  9.0616e-02, -1.1903e-01,\n",
      "          1.2831e-01,  2.0243e-01, -1.5483e-01, -3.9467e-01, -1.0988e-01,\n",
      "         -2.8011e-01, -2.8822e-01, -1.9205e-01,  3.7496e-01,  2.6868e-01,\n",
      "          3.0722e-01, -3.6389e-01, -1.3949e-01, -3.8626e-01,  4.8185e-02,\n",
      "         -1.4912e-01,  2.5873e-03,  1.9613e-02,  9.0817e-02,  6.7626e-02,\n",
      "          2.7030e-01,  2.2821e-01, -4.0115e-01, -9.2438e-02, -1.4223e-01,\n",
      "         -3.0181e-01,  9.2092e-02,  2.2638e-02,  1.7860e-01, -2.5587e-01,\n",
      "          2.5293e-02, -5.6463e-02,  6.7215e-02,  2.1797e-01],\n",
      "        [-2.2124e-01,  1.9299e-01,  2.4253e-04,  2.8866e-01,  8.4397e-02,\n",
      "         -8.2054e-01,  3.5372e-01, -1.6754e-01,  7.0555e-03,  7.2767e-02,\n",
      "          1.5666e-01,  2.4922e-02,  4.3216e-02,  9.4616e-02,  2.0979e-01,\n",
      "          1.0264e-01, -4.7957e-01,  1.8375e-01, -2.6914e-01, -3.0953e-01,\n",
      "         -5.3830e-02, -4.9275e-03, -2.3006e-01,  3.2321e-01,  2.2447e-01,\n",
      "          6.9532e-02, -8.4025e-02, -2.1816e-01,  2.9627e-03,  1.8922e-01,\n",
      "         -3.1928e-01, -1.3946e-01, -9.1560e-02,  1.3182e-01, -5.8426e-01,\n",
      "         -2.5182e-01, -1.9569e-01, -6.4524e-03, -1.5726e-02,  8.9741e-02,\n",
      "          6.0190e-02,  3.0832e-01, -9.5307e-02,  1.8634e-01,  3.7600e-02,\n",
      "          3.8606e-02,  1.0835e-01, -3.5714e-01,  3.9925e-02, -5.8876e-02,\n",
      "         -1.3223e-01, -1.9282e-01,  1.5643e-01, -3.8913e-01, -2.5898e-01,\n",
      "          2.1401e-01,  8.0954e-02,  2.1569e-02, -2.6534e-01, -5.7614e-01,\n",
      "         -1.4055e-02, -2.2026e-01, -1.5895e-01,  1.7726e-02],\n",
      "        [-1.6426e-01,  1.4003e-01, -8.8365e-02,  3.0266e-01,  1.7275e-01,\n",
      "          2.2520e-01,  5.0727e-02, -3.2334e-01, -6.9956e-02,  2.4008e-01,\n",
      "         -1.1305e-01, -2.2326e-02, -7.4975e-03, -8.4919e-02,  1.5443e-02,\n",
      "         -1.2606e-01,  2.0109e-02, -4.2728e-01, -2.8557e-01,  5.8531e-02,\n",
      "         -6.8194e-01,  7.5224e-02,  1.3791e-01, -4.7073e-01, -5.7035e-01,\n",
      "         -1.2981e-01, -5.6359e-01,  3.0950e-01,  2.5779e-01, -5.2355e-01,\n",
      "         -1.0960e-03,  2.5948e-01, -5.3284e-02, -1.9153e-01,  2.3395e-01,\n",
      "         -2.4020e-02,  1.7210e-01,  1.2561e-01,  1.5555e-01, -1.0072e+00,\n",
      "         -6.7895e-01,  1.3365e-01,  1.3523e-01, -7.1848e-01, -3.6002e-01,\n",
      "         -6.0397e-02,  2.4738e-01, -9.7228e-02, -3.5420e-01, -3.4661e-02,\n",
      "          1.4022e-01, -1.6501e-01,  1.9465e-01,  1.0492e-01,  2.4286e-01,\n",
      "         -4.1158e-01, -1.6403e-01, -3.1374e-01, -3.0286e-01,  2.9083e-01,\n",
      "          1.7839e-02, -7.4975e-03,  3.5841e-01,  2.1549e-03],\n",
      "        [ 1.5568e-01, -5.6288e-01, -9.1095e-03, -7.8953e-01,  2.1116e-01,\n",
      "          4.0612e-01,  4.7517e-01,  3.6271e-02, -5.6020e-01,  1.9581e-02,\n",
      "         -2.3408e-02,  9.5860e-02, -5.6651e-01, -2.9808e-01,  1.5085e-01,\n",
      "          3.7317e-02,  4.5119e-01,  5.9373e-02,  3.0487e-01,  3.7690e-01,\n",
      "         -2.6565e-01, -8.8169e-02, -2.2719e-01, -1.3493e-02,  2.2752e-01,\n",
      "         -4.1182e-03,  9.2950e-02, -3.0529e-02,  7.5134e-02,  1.2528e-01,\n",
      "         -2.5846e-01, -1.8348e-01,  1.4781e-01,  2.6832e-01, -1.0924e-01,\n",
      "         -3.4218e-01,  1.5943e-01, -4.4045e-02,  1.0044e-01, -1.5724e-02,\n",
      "         -3.5157e-02,  2.9980e-01, -2.0421e-01,  1.9407e-01,  1.3194e-01,\n",
      "          1.4898e-01, -2.1514e-01,  3.0854e-01,  1.1375e-01, -8.4681e-02,\n",
      "         -2.5451e-01, -5.8011e-01,  5.4705e-02,  2.8234e-02, -4.0868e-01,\n",
      "          9.4143e-02,  4.4907e-02, -5.1416e-02,  2.9090e-01,  2.7267e-01,\n",
      "          7.0452e-02, -1.1365e-01, -3.2090e-01, -2.6326e-01],\n",
      "        [ 4.5904e-02, -4.8645e-01,  3.8021e-02,  3.5909e-02,  1.2344e-02,\n",
      "         -1.3801e-01, -4.1686e-01,  2.0088e-01,  2.4951e-01, -5.3983e-01,\n",
      "         -2.2407e-01,  2.8333e-02, -5.7501e-01,  1.5058e-01, -2.9041e-01,\n",
      "         -1.1890e-01,  3.0154e-01, -2.7475e-01,  3.2222e-01, -5.6512e-01,\n",
      "         -1.0825e-01,  1.3312e-01,  1.3757e-01, -3.7869e-01, -6.0113e-01,\n",
      "         -7.0115e-03,  1.0170e-01, -4.0146e-03,  1.6551e-01,  1.1241e-01,\n",
      "          8.7547e-02,  6.3367e-02, -1.0748e-01,  4.6925e-02, -8.1356e-02,\n",
      "          1.1574e-01, -1.8317e-03, -9.2695e-02,  2.2503e-01, -4.9300e-01,\n",
      "          4.1996e-02, -6.6670e-01,  1.8196e-03,  4.1828e-01,  4.7059e-02,\n",
      "         -6.9067e-01,  5.5427e-02,  3.4895e-01, -6.2561e-01,  9.4802e-02,\n",
      "          4.5938e-02, -2.0026e-01, -6.0177e-01, -3.7648e-01,  1.4486e-01,\n",
      "         -6.3882e-01,  1.8246e-03, -1.0702e-01,  3.4466e-01,  1.5455e-01,\n",
      "          5.7003e-02,  9.3708e-02,  6.6067e-04, -9.9799e-02],\n",
      "        [ 6.1684e-02,  1.4166e-01, -6.1174e-02,  1.9198e-01, -4.0831e-01,\n",
      "         -8.9670e-02, -4.8238e-01, -3.2712e-01,  1.3764e-01, -5.0701e-02,\n",
      "          1.3196e-01,  9.6747e-03,  1.7740e-01, -2.1263e-01, -2.9596e-01,\n",
      "         -3.3786e-01, -2.9208e-01,  1.4134e-01, -7.0943e-02,  3.0361e-01,\n",
      "         -1.4609e-01, -4.1772e-01, -1.4963e-01,  4.8759e-01,  2.2491e-01,\n",
      "          1.1033e-01, -2.9888e-01,  4.3426e-01, -2.1219e-01, -2.1589e-01,\n",
      "         -8.4523e-02, -4.2005e-01,  3.7841e-02, -1.2018e-01, -1.0020e-01,\n",
      "         -5.2981e-02, -4.4629e-02, -1.7298e-01, -2.2239e-01,  6.4012e-02,\n",
      "          1.2726e-01, -5.4876e-01,  8.4839e-02,  1.3753e-01, -2.6040e-02,\n",
      "          8.3261e-02, -4.8095e-02,  5.9602e-02,  1.9146e-01,  3.5013e-03,\n",
      "          1.6432e-01, -1.8653e-02,  5.8126e-02,  3.0070e-01,  1.7603e-01,\n",
      "          8.4126e-02, -2.4719e-01, -5.9437e-02, -2.3141e-01,  4.6265e-02,\n",
      "         -4.3344e-01,  6.9785e-02,  1.4470e-01,  2.6731e-01],\n",
      "        [-1.7694e-01, -1.7108e-02,  5.7231e-02, -1.4487e-01,  1.8523e-01,\n",
      "         -7.0506e-01, -8.2036e-01, -2.1193e-02, -1.4719e-01,  5.5746e-02,\n",
      "          8.4871e-02, -1.2194e-02,  4.1434e-02,  9.6762e-02,  2.4448e-01,\n",
      "          1.0026e-01, -1.1042e-01, -2.8991e-01, -2.7308e-05, -4.3871e-01,\n",
      "          1.6286e-01,  1.3034e-01,  1.1829e-01, -1.5466e-01, -8.2291e-03,\n",
      "         -5.7580e-02,  6.7032e-02, -1.1604e-01, -2.6073e-01,  7.2136e-03,\n",
      "         -1.2688e-01,  2.6032e-02,  7.5013e-02,  2.4368e-01,  3.0767e-01,\n",
      "         -2.0363e-01, -3.5800e-01,  2.0070e-01, -1.6456e-02, -3.6264e-02,\n",
      "          1.6106e-01, -3.3404e-01,  1.1806e-01, -5.9078e-02,  4.9206e-02,\n",
      "          8.0682e-02,  6.5699e-02,  7.3144e-02,  1.0389e-01, -1.2388e-01,\n",
      "         -7.1775e-01,  1.1377e-01,  1.1348e-01, -2.2616e-01, -3.6994e-01,\n",
      "         -3.9498e-01,  1.4411e-01, -1.3521e-01, -1.9544e-01,  2.0257e-02,\n",
      "          1.2982e-01,  7.2707e-02, -3.7381e-01,  1.1019e-01],\n",
      "        [-5.6233e-01,  1.9261e-01, -9.3843e-02, -1.1009e-01,  2.5975e-02,\n",
      "         -4.3632e-01,  1.3559e-01, -2.6285e-01,  1.8383e-01,  2.6078e-02,\n",
      "         -2.1267e-01, -1.7509e-02,  1.8997e-01,  1.6635e-01,  1.3951e-01,\n",
      "          5.4394e-03,  2.1942e-01, -4.8150e-01, -5.3644e-01,  9.4664e-04,\n",
      "          1.7404e-02,  1.7290e-01,  2.4962e-01, -8.0307e-01,  6.6750e-02,\n",
      "         -4.7611e-02, -2.7503e-01, -2.6955e-01, -2.8963e-01, -2.7714e-01,\n",
      "         -3.5127e-01,  2.1836e-01,  9.0993e-02, -2.0642e-02, -1.0929e-01,\n",
      "          1.4901e-01,  1.4943e-01, -4.5149e-02, -6.4003e-01,  2.0984e-01,\n",
      "         -1.9226e-01,  2.6029e-01,  1.0379e-01, -2.8974e-01, -9.1295e-02,\n",
      "          1.2317e-01, -2.5966e-01, -4.8696e-03,  1.2854e-01, -4.6766e-02,\n",
      "          1.1992e-01, -4.8001e-01,  6.0453e-02,  1.4551e-01,  1.5308e-01,\n",
      "          1.5150e-01, -2.0412e-01,  1.0906e-01, -1.9733e-02, -5.2851e-02,\n",
      "         -4.5070e-02, -6.3583e-02, -8.2098e-02, -3.9426e-01]], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0839,  0.0421,  0.0889, -0.0485, -0.0260,  0.1981, -0.1224,  0.1612,\n",
      "        -0.1202, -0.0884], device='cuda:0', requires_grad=True)\n",
      "CPU times: user 6.25 s, sys: 0 ns, total: 6.25 s\n",
      "Wall time: 6.12 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataloader = DataLoader(train_ds,batch_size=args.batch *4)\n",
    "optimizer = torch.optim.Adam(params = model.parameters(), lr=args.lr*4)\n",
    "%time train(model, optimizer, dataloader, gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataParallel\n",
    "single process, multiple GPUs\n",
    "\n",
    "    This container parallelizes the application of the given :attr:`module` by\n",
    "    splitting the input across the specified devices by chunking in the batch\n",
    "    dimension (other objects will be copied once per device). In the forward\n",
    "    pass, the module is replicated on each device, and each replica handles a\n",
    "    portion of the input. During the backwards pass, gradients from each replica\n",
    "    are summed into the original module.\n",
    "\n",
    "Source: https://pytorch.org/docs/stable/_modules/torch/nn/parallel/data_parallel.html\n",
    "\n",
    "The batch size should be larger than the number of GPUs used.\n",
    "\n",
    "\n",
    "1. This is not very optimal as every forward run transfers the model and data portion between GPUs. \n",
    "1. Unless the processing in the module takes significant amount of time, this is not very useful.\n",
    "1. This is even slower than single GPU for simpler neural nets.\n",
    "\n",
    "        inputs, kwargs = self.scatter(inputs, kwargs, self.device_ids)\n",
    "        if len(self.device_ids) == 1:\n",
    "            return self.module(*inputs[0], **kwargs[0])\n",
    "        replicas = self.replicate(self.module, self.device_ids[:len(inputs)])\n",
    "        outputs = self.parallel_apply(replicas, inputs, kwargs)\n",
    "        return self.gather(outputs, self.output_device)\n",
    "\n",
    "Issues : https://medium.com/huggingface/training-larger-batches-practical-tips-on-1-gpu-multi-gpu-distributed-setups-ec88c3e51255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/3750 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3750/3750 [00:28<00:00, 130.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss at epoch 0 is 0.02045580744743347\n",
      "Parameter containing:\n",
      "tensor([[-0.0076, -0.0294,  0.0116,  ..., -0.0147, -0.0065,  0.0233],\n",
      "        [ 0.0011, -0.0171,  0.0117,  ..., -0.0304,  0.0206, -0.0230],\n",
      "        [ 0.0346, -0.0024, -0.0289,  ...,  0.0125,  0.0123,  0.0176],\n",
      "        ...,\n",
      "        [-0.0225, -0.0271,  0.0311,  ..., -0.0336,  0.0192, -0.0331],\n",
      "        [ 0.0084,  0.0030, -0.0014,  ...,  0.0080, -0.0274, -0.0197],\n",
      "        [-0.0115, -0.0345,  0.0073,  ..., -0.0159, -0.0313,  0.0245]],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0054,  0.0412,  0.1164,  0.2572,  0.1048, -0.0464,  0.0366,  0.0670,\n",
      "        -0.0300,  0.1368,  0.0753, -0.0254,  0.0471,  0.2325, -0.0971, -0.0404,\n",
      "        -0.0392, -0.0520,  0.0278,  0.0607,  0.0581,  0.0866, -0.0204, -0.0930,\n",
      "        -0.0066, -0.0504,  0.1568,  0.0442,  0.0608,  0.0227,  0.0414, -0.0266,\n",
      "        -0.0021,  0.0406,  0.2628, -0.0318,  0.0794, -0.0016, -0.0291,  0.0027,\n",
      "         0.1672,  0.1766, -0.1432, -0.0209,  0.0291,  0.1707, -0.0572, -0.0470,\n",
      "         0.0015,  0.1858,  0.0079,  0.1569, -0.0485,  0.0831, -0.1202,  0.0056,\n",
      "        -0.0815,  0.1430,  0.0411, -0.0904,  0.0769,  0.2398,  0.0329, -0.0691],\n",
      "       device='cuda:0', requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-1.3031e-01, -1.6129e-02, -1.3328e-01, -3.9509e-01,  1.3558e-01,\n",
      "          1.5005e-01,  1.1709e-01, -1.3630e-01, -3.1166e-02, -1.0301e-01,\n",
      "         -8.7054e-02, -8.1913e-02, -1.8649e-01, -1.7280e-01,  1.0673e-01,\n",
      "          1.9172e-01, -2.6138e-01,  6.1923e-02, -4.1516e-01,  1.0055e-01,\n",
      "          1.5154e-01, -3.2625e-01,  3.5880e-03, -5.8762e-02, -2.2151e-01,\n",
      "          5.2168e-02,  2.3289e-01,  1.4570e-01,  3.2134e-02, -9.3531e-02,\n",
      "         -2.9009e-01,  4.7320e-02, -1.6963e-01, -2.8345e-02,  7.1252e-03,\n",
      "          1.2519e-01,  2.4405e-01, -6.6345e-02, -3.1886e-01, -1.6200e-01,\n",
      "         -1.3640e-01, -1.3928e-01, -1.9060e-01, -1.2761e-01, -4.8601e-01,\n",
      "         -1.0759e-01,  1.0009e-01,  1.8932e-01,  9.4559e-02, -1.5515e-01,\n",
      "         -1.5987e-01,  1.9070e-01,  1.8308e-01, -3.3812e-01,  2.6395e-01,\n",
      "          1.1858e-01,  1.0095e-01, -1.8583e-01, -4.2502e-01,  1.6557e-01,\n",
      "         -2.2935e-02,  6.9454e-02, -1.7852e-01, -2.9700e-01],\n",
      "        [ 7.0088e-02, -3.6812e-02,  1.9653e-01,  2.0456e-02,  2.8840e-01,\n",
      "          1.0826e-02,  9.6320e-02, -1.9773e-01,  2.0085e-02,  4.4847e-01,\n",
      "         -3.1878e-01, -1.1891e-01,  2.3409e-01,  1.5483e-01, -4.8287e-02,\n",
      "         -2.4586e-01,  1.6195e-04, -3.6982e-01,  1.0420e-01, -1.2412e-01,\n",
      "         -9.8112e-02,  2.1018e-01, -7.6645e-02, -2.7156e-01, -4.5248e-02,\n",
      "         -6.8502e-03,  1.4594e-02, -1.4003e-01, -6.1684e-02, -3.3435e-01,\n",
      "         -7.4138e-02,  1.8229e-02,  1.3869e-01,  1.2717e-01,  6.4953e-02,\n",
      "          7.6789e-03,  1.2392e-02, -3.2763e-01,  1.8896e-01,  6.6190e-02,\n",
      "         -7.7720e-02, -2.7736e-01,  1.0073e-01, -2.8712e-01,  2.2923e-01,\n",
      "          7.4450e-02,  2.5111e-01, -3.9923e-01, -6.6675e-02,  2.5942e-01,\n",
      "          3.1240e-03, -1.3125e-01, -1.6894e-01,  1.6365e-01, -1.1396e-01,\n",
      "         -1.4594e-02, -3.2778e-01, -7.5133e-02,  3.7664e-02,  8.4810e-02,\n",
      "          6.6822e-02, -1.4681e-01, -1.3725e-01,  1.6001e-01],\n",
      "        [ 1.6612e-01,  3.2513e-01,  1.8635e-01, -5.1001e-02,  6.9629e-02,\n",
      "          2.0819e-01, -1.1207e-01, -3.3736e-01, -1.7839e-02, -4.6647e-01,\n",
      "          1.0024e-01,  9.4199e-03, -7.8011e-02, -2.2752e-01,  1.4168e-01,\n",
      "         -2.7043e-02,  1.0944e-01, -1.5389e-01,  2.0013e-01,  1.8271e-01,\n",
      "          1.1592e-01, -2.5654e-01, -4.8030e-02, -7.9756e-02, -2.7262e-01,\n",
      "          7.7526e-02,  7.9965e-02,  5.9215e-02,  1.2771e-01, -1.5954e-01,\n",
      "          1.1931e-01,  9.8676e-02,  2.5601e-01,  1.2940e-01, -4.8974e-01,\n",
      "         -7.8050e-02,  9.3785e-02, -3.5584e-02,  5.4199e-02, -8.2151e-02,\n",
      "         -1.4670e-01,  2.3231e-01, -9.6423e-02, -2.2462e-01, -6.2560e-02,\n",
      "         -6.4354e-01,  7.4242e-02, -1.8723e-02, -5.2409e-02,  2.3318e-01,\n",
      "          1.7227e-01, -1.7586e-01, -2.0219e-01, -4.4304e-01, -1.4480e-01,\n",
      "          1.6593e-01,  1.4884e-01,  9.9757e-02,  5.8118e-02, -1.8819e-02,\n",
      "          7.1020e-02,  2.5600e-02,  4.1632e-02,  1.8750e-01],\n",
      "        [ 1.1812e-01, -8.0676e-02,  3.3442e-02, -1.5722e-03,  2.4787e-01,\n",
      "          7.9826e-02,  1.2535e-01,  1.7845e-01, -2.5227e-01, -3.7994e-01,\n",
      "         -1.5777e-01, -1.1403e-01, -2.6780e-01, -2.3443e-01, -1.3381e-01,\n",
      "          4.2483e-02,  2.5116e-01, -2.4176e-01,  2.3069e-01,  1.1212e-01,\n",
      "         -2.2933e-01,  1.6208e-01, -9.6627e-02,  1.0759e-01,  5.4696e-02,\n",
      "         -9.9026e-02,  1.0267e-01, -1.3847e-01,  2.0978e-01, -1.3657e-01,\n",
      "         -1.6442e-01, -8.4690e-02, -2.5078e-01, -2.4249e-01, -2.3046e-01,\n",
      "         -8.4109e-02,  6.6406e-02, -1.8728e-01,  2.3362e-01,  3.4617e-02,\n",
      "         -4.4072e-01, -9.4300e-02,  3.9578e-02,  1.1727e-01,  1.5069e-01,\n",
      "          1.0733e-01, -8.0524e-02,  6.0211e-02, -2.7445e-02, -1.4979e-01,\n",
      "         -6.8164e-02, -1.7559e-01, -1.8492e-01, -2.7643e-01,  2.4496e-02,\n",
      "          1.4933e-01,  3.9013e-02,  1.5140e-01,  1.1587e-01,  1.1903e-01,\n",
      "         -9.0856e-02, -3.4981e-01, -6.5614e-02,  2.6177e-01],\n",
      "        [ 7.2375e-02, -3.9743e-01,  9.7479e-02,  1.3410e-01, -5.0769e-02,\n",
      "         -5.1941e-01, -2.2736e-01, -3.4493e-03,  4.1518e-02,  8.3599e-02,\n",
      "          1.4584e-01,  1.0678e-01,  1.3710e-01,  4.3321e-02, -1.9500e-01,\n",
      "          6.6526e-02,  2.4111e-01,  1.6388e-01, -2.0831e-01, -3.8143e-01,\n",
      "          9.4220e-02,  1.7784e-03, -6.8844e-02, -1.4206e-01, -3.6132e-02,\n",
      "         -5.4207e-02, -2.0537e-01,  2.8501e-02,  1.5286e-01,  2.8992e-03,\n",
      "          1.3699e-01,  5.9367e-02, -1.3918e-01,  1.6431e-01, -8.3837e-02,\n",
      "         -2.8385e-01, -5.2426e-01,  1.4225e-01, -2.9683e-02, -2.2269e-01,\n",
      "          1.9305e-01,  2.5436e-01, -2.8502e-01, -1.2746e-01, -1.2357e-02,\n",
      "          2.2624e-01, -3.9456e-02,  3.9812e-02,  1.0953e-01, -2.6734e-01,\n",
      "         -2.6686e-01, -9.8499e-02,  1.9148e-01, -4.5320e-01, -4.3423e-01,\n",
      "         -1.9125e-01,  9.4798e-04, -4.3438e-01,  2.7079e-01, -1.7620e-02,\n",
      "         -1.2257e-01,  2.2675e-01,  2.5303e-01, -1.1492e-01],\n",
      "        [ 9.9139e-03,  1.6887e-01, -8.8760e-02,  9.7029e-02, -1.4569e-01,\n",
      "         -1.7281e-01,  1.1163e-01,  2.3714e-02, -3.4115e-01,  1.1297e-01,\n",
      "          7.7770e-02,  2.8355e-02, -4.9913e-01,  1.5812e-01,  5.2181e-02,\n",
      "          8.4770e-03, -3.1411e-01, -1.1991e-01,  1.1447e-01,  2.6035e-01,\n",
      "         -1.9782e-01,  1.1281e-01, -1.4885e-03,  5.9524e-02,  1.2428e-01,\n",
      "          7.8318e-02,  2.4923e-01, -3.1247e-01, -3.4750e-01,  2.7094e-02,\n",
      "         -1.8834e-01,  9.6833e-02,  3.6329e-02, -5.0476e-01,  5.4720e-01,\n",
      "          8.7286e-02, -7.6003e-02, -3.7423e-02, -3.8668e-01,  3.6990e-02,\n",
      "         -1.2552e-01,  1.0313e-01, -2.5869e-01,  2.4333e-01,  8.4769e-02,\n",
      "          1.1783e-01, -4.2393e-01, -1.1835e-01,  9.6557e-02,  1.8150e-01,\n",
      "         -3.8246e-01,  1.5360e-01,  4.7994e-02,  5.7464e-01, -1.8446e-01,\n",
      "          1.4350e-01, -1.0389e-01, -2.3092e-01,  2.9301e-02, -3.5563e-02,\n",
      "          1.0551e-01,  6.4391e-02,  1.0468e-01, -1.1368e-01],\n",
      "        [-1.0538e-01, -2.3738e-01,  1.8682e-01, -5.4278e-01,  2.1058e-01,\n",
      "         -2.1565e-01, -2.5050e-02, -2.1898e-01,  1.8914e-01, -8.4236e-02,\n",
      "          2.5135e-01, -9.0666e-02,  2.7898e-02, -3.9758e-01,  1.3456e-01,\n",
      "          9.8560e-02, -2.8890e-01,  2.1978e-01, -5.0337e-01, -2.4869e-01,\n",
      "          1.5514e-01, -5.1556e-02,  5.8886e-02,  7.0511e-02,  1.2976e-01,\n",
      "         -3.5649e-02,  8.1865e-02, -3.3063e-02, -1.9172e-01, -4.3612e-02,\n",
      "          1.2718e-01, -7.1994e-02,  7.6440e-03, -2.4085e-01,  7.8128e-02,\n",
      "          6.0666e-02, -2.9503e-01, -1.7614e-01, -4.0897e-01,  1.6759e-01,\n",
      "          7.7770e-02,  1.9435e-01, -1.9168e-01, -1.7444e-01, -8.4546e-02,\n",
      "         -2.8236e-01,  2.2660e-01, -1.6396e-01, -7.2954e-02,  2.1514e-01,\n",
      "          1.2499e-01, -9.7335e-02,  1.2527e-01,  3.6670e-01,  4.0411e-02,\n",
      "         -3.3848e-01, -1.2134e-01, -4.3567e-01, -3.8328e-01, -1.6872e-01,\n",
      "         -2.4447e-01, -2.9446e-01,  1.2340e-01, -4.7517e-02],\n",
      "        [-2.2166e-01,  2.0308e-01, -2.8736e-02,  2.0280e-01,  2.3407e-02,\n",
      "          5.1064e-03, -1.8297e-03,  1.4646e-01,  1.0034e-01,  2.5052e-01,\n",
      "         -5.0994e-02, -1.0232e-01,  1.2715e-01,  2.4616e-01, -3.2985e-01,\n",
      "         -1.9327e-01, -8.1235e-02, -2.3710e-01, -1.7754e-02, -2.0863e-03,\n",
      "          7.2099e-02,  1.0714e-01,  1.0895e-01, -2.6244e-01, -1.3136e-02,\n",
      "         -3.9405e-01,  5.0661e-02,  1.8398e-01,  1.3677e-01,  1.5457e-01,\n",
      "          9.9135e-02,  1.5967e-02, -5.7968e-02, -5.5615e-02, -1.8309e-01,\n",
      "         -3.9035e-01,  2.1814e-01,  1.1787e-01, -1.1518e-01, -2.3966e-01,\n",
      "          2.4417e-01, -3.6314e-01, -5.3557e-02, -3.1018e-02, -2.2521e-01,\n",
      "         -7.1001e-02,  3.3774e-02,  1.0221e-01,  9.4438e-02, -1.8218e-01,\n",
      "          1.3124e-01, -2.4277e-02, -7.9964e-02, -1.8188e-01,  9.0671e-02,\n",
      "          1.0416e-01,  1.7721e-02,  2.7210e-01, -3.2616e-01, -7.8825e-02,\n",
      "          5.6969e-02,  2.2818e-01, -2.9062e-01,  2.7857e-01],\n",
      "        [ 1.3075e-01,  3.1025e-02, -2.0968e-01, -5.0660e-02, -3.6812e-01,\n",
      "         -3.7571e-02,  1.0399e-01, -6.8061e-02,  7.7358e-02, -5.2895e-01,\n",
      "          6.6505e-04,  7.7487e-02,  8.3449e-02, -3.3312e-01,  1.5732e-01,\n",
      "          3.6158e-03,  4.9966e-02, -3.6986e-02, -2.0656e-02, -8.2623e-02,\n",
      "         -2.6360e-01,  1.0339e-01,  6.3380e-02,  2.2453e-03,  1.3164e-01,\n",
      "          2.0445e-01, -2.9790e-01, -2.6590e-01, -3.1912e-01,  8.5310e-02,\n",
      "          8.4632e-02,  8.2232e-03,  1.1691e-01, -5.8143e-02, -2.5394e-01,\n",
      "          1.0670e-01, -2.2631e-01,  1.6114e-01, -1.5641e-02, -1.0141e-01,\n",
      "         -1.9319e-01, -2.2884e-01,  2.0125e-01,  6.3231e-02,  3.5409e-03,\n",
      "         -3.0741e-02,  9.5126e-03, -4.9490e-03,  5.1753e-02, -2.8040e-01,\n",
      "         -1.9995e-02, -1.8465e-01,  1.9722e-01, -1.2196e-01,  1.0209e-01,\n",
      "          8.0116e-02,  4.3199e-02, -3.0692e-01,  2.8222e-02,  1.5010e-01,\n",
      "         -3.3074e-01, -4.0950e-01,  7.9764e-02,  9.5582e-02],\n",
      "        [ 1.7719e-02, -3.5950e-01, -6.5136e-01,  1.2373e-01, -4.8610e-01,\n",
      "         -1.0646e-01, -1.3233e-01,  2.0978e-01, -6.4138e-03, -1.9847e-02,\n",
      "         -5.5301e-01, -1.3596e-02,  8.3606e-03, -2.0398e-03,  2.3996e-02,\n",
      "         -8.1309e-02, -3.5381e-02,  1.3009e-01, -9.4386e-02, -2.2946e-01,\n",
      "         -7.7949e-02, -1.4892e-01,  3.8671e-02, -2.0380e-01,  2.7002e-02,\n",
      "          4.6133e-02, -2.3461e-01,  1.4919e-01,  1.7874e-01,  1.6167e-01,\n",
      "         -1.6963e-01,  1.1327e-01, -4.2752e-01,  2.4987e-01,  1.8481e-01,\n",
      "         -1.3493e-01,  1.7424e-01,  1.6302e-04,  3.4370e-02,  1.9687e-01,\n",
      "         -9.2548e-03,  8.1755e-03,  1.0137e-01,  6.1935e-02,  1.9480e-01,\n",
      "          2.0270e-01, -2.6016e-01,  1.8590e-01,  1.1292e-01, -2.8182e-01,\n",
      "          1.1960e-01, -1.2698e-01, -8.5658e-02, -3.6600e-02, -2.4463e-03,\n",
      "         -2.4502e-01,  1.4493e-01, -1.9849e-02, -2.0847e-02, -1.8709e-01,\n",
      "         -1.0231e-02,  6.7389e-02, -7.7403e-02, -5.8505e-01]], device='cuda:0',\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0490, -0.0540, -0.0515, -0.1634,  0.1261,  0.1936, -0.0228,  0.0514,\n",
      "        -0.1252, -0.0546], device='cuda:0', requires_grad=True)\n",
      "CPU times: user 31.1 s, sys: 4.19 s, total: 35.3 s\n",
      "Wall time: 28.8 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = LinearModel(784,10,verbose = False).to(gpu)\n",
    "model = torch.nn.DataParallel(model)\n",
    "\n",
    "#Each batch is split into number of gpus and data is scattered. Use verbose = True to verify parallel processing\n",
    "dataloader = DataLoader(train_ds,batch_size=args.batch)\n",
    "optimizer = torch.optim.Adam(params = model.parameters(), lr=args.lr)\n",
    "\n",
    "%time train(model, optimizer, dataloader, gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using Higher batch size\n",
    "Even for higher batch sizes, it's still slower than single GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 12/938 [00:00<00:08, 110.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 938/938 [00:08<00:00, 110.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss at epoch 0 is 0.02199617028236389\n",
      "CPU times: user 9.62 s, sys: 620 ms, total: 10.2 s\n",
      "Wall time: 8.5 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#Batch size can be increased to take advantage of the parallel processing\n",
    "dataloader = DataLoader(train_ds,batch_size=args.batch *4)\n",
    "#increase the lr for high batch size. (Provide proof for this)\n",
    "optimizer = torch.optim.Adam(params = model.parameters(), lr=args.lr * 4)\n",
    "\n",
    "%time train(model, optimizer, dataloader, gpu)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
